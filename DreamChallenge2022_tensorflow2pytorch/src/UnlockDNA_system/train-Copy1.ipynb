{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e977b28-3aa9-43bf-ab46-4c6eb007692d",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cb95f7-155e-4444-a35d-43685a18e6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muntakimrafi/anaconda3/envs/dream_autosome/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from models.ResNet_model import *\n",
    "#from models.{team_name}_model import *\n",
    "from utils import *\n",
    "import h5py\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d31f34-fa85-4826-8703-c969a07c6c5d",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d311690c-7ff4-4a0d-a890-1483e452e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('X_train.h5','r')\n",
    "X_train = h5f['X_train'][:]\n",
    "h5f.close()\n",
    "h5f = h5py.File('X_val.h5','r')\n",
    "X_val = h5f['X_val'][:]\n",
    "h5f.close()\n",
    "h5f = h5py.File('y_train.h5','r')\n",
    "y_train = h5f['y_train'][:]\n",
    "h5f.close()\n",
    "h5f = h5py.File('y_val.h5','r')\n",
    "y_val = h5f['y_val'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a79c55b-374e-4886-ad26-3217702508f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6065331, 4, 110)\n",
      "(673926, 4, 110)\n",
      "(6065331,)\n",
      "(673926,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd107c-d29d-40ee-bea8-159b0e7d66df",
   "metadata": {},
   "source": [
    "# create dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d27c739-1dee-4f1c-96bc-6a94bbbe6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = createDataLoader(X_train, y_train, num_workers=0, batch_size=1024, shuffle=True, drop_last=True, \n",
    "                           random_seed = 42)\n",
    "valLoader = createDataLoader(X_val, y_val, num_workers=0, batch_size=1024, shuffle=True, drop_last=True, random_seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e5612-3584-4bc7-a575-4b77c44e08aa",
   "metadata": {},
   "source": [
    "# define all the possible options for different layers that your model can accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf15907-5a65-49c4-a960-fb004dfb96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1s = [FirstLayers(4, 64, 7, 1, 'same'), ]\n",
    "l2s = [ResidualLayers(ResidualBlock, [3,4,6,3]), ]\n",
    "l3s = [FinalLayers(14, 512, 1), ]\n",
    "lossFunctions = [torch.nn.MSELoss().to(device),]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a021d0-a7c6-48fb-a015-738c1fc77e04",
   "metadata": {},
   "source": [
    "# choose a specific combination from all possible options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0207c2a5-0606-4eb4-ac66-ea30134d956b",
   "metadata": {},
   "source": [
    "##### after you finish defining l1s, l2s, ... ... ..., lossFunctions, lrs for your model you can just run a for loop to create all possible model combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fcef2c-d9a6-4e86-81f6-3d530abd27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [l1s[0], l2s[0], l3s[0]]\n",
    "\n",
    "model = PrixFixeNet(layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1eec1f-5e44-4fa5-aa5c-0d33539f83a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 110]           1,856\n",
      "       BatchNorm1d-2              [-1, 64, 110]             128\n",
      "              ReLU-3              [-1, 64, 110]               0\n",
      "       FirstLayers-4              [-1, 64, 110]               0\n",
      "            Conv1d-5              [-1, 64, 110]          12,352\n",
      "       BatchNorm1d-6              [-1, 64, 110]             128\n",
      "              ReLU-7              [-1, 64, 110]               0\n",
      "            Conv1d-8              [-1, 64, 110]          12,352\n",
      "       BatchNorm1d-9              [-1, 64, 110]             128\n",
      "             ReLU-10              [-1, 64, 110]               0\n",
      "    ResidualBlock-11              [-1, 64, 110]               0\n",
      "           Conv1d-12              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-13              [-1, 64, 110]             128\n",
      "             ReLU-14              [-1, 64, 110]               0\n",
      "           Conv1d-15              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-16              [-1, 64, 110]             128\n",
      "             ReLU-17              [-1, 64, 110]               0\n",
      "    ResidualBlock-18              [-1, 64, 110]               0\n",
      "           Conv1d-19              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-20              [-1, 64, 110]             128\n",
      "             ReLU-21              [-1, 64, 110]               0\n",
      "           Conv1d-22              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-23              [-1, 64, 110]             128\n",
      "             ReLU-24              [-1, 64, 110]               0\n",
      "    ResidualBlock-25              [-1, 64, 110]               0\n",
      "           Conv1d-26              [-1, 128, 55]          24,704\n",
      "      BatchNorm1d-27              [-1, 128, 55]             256\n",
      "             ReLU-28              [-1, 128, 55]               0\n",
      "           Conv1d-29              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-30              [-1, 128, 55]             256\n",
      "           Conv1d-31              [-1, 128, 55]           8,320\n",
      "      BatchNorm1d-32              [-1, 128, 55]             256\n",
      "             ReLU-33              [-1, 128, 55]               0\n",
      "    ResidualBlock-34              [-1, 128, 55]               0\n",
      "           Conv1d-35              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-36              [-1, 128, 55]             256\n",
      "             ReLU-37              [-1, 128, 55]               0\n",
      "           Conv1d-38              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-39              [-1, 128, 55]             256\n",
      "             ReLU-40              [-1, 128, 55]               0\n",
      "    ResidualBlock-41              [-1, 128, 55]               0\n",
      "           Conv1d-42              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-43              [-1, 128, 55]             256\n",
      "             ReLU-44              [-1, 128, 55]               0\n",
      "           Conv1d-45              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-46              [-1, 128, 55]             256\n",
      "             ReLU-47              [-1, 128, 55]               0\n",
      "    ResidualBlock-48              [-1, 128, 55]               0\n",
      "           Conv1d-49              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-50              [-1, 128, 55]             256\n",
      "             ReLU-51              [-1, 128, 55]               0\n",
      "           Conv1d-52              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-53              [-1, 128, 55]             256\n",
      "             ReLU-54              [-1, 128, 55]               0\n",
      "    ResidualBlock-55              [-1, 128, 55]               0\n",
      "           Conv1d-56              [-1, 256, 28]          98,560\n",
      "      BatchNorm1d-57              [-1, 256, 28]             512\n",
      "             ReLU-58              [-1, 256, 28]               0\n",
      "           Conv1d-59              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-60              [-1, 256, 28]             512\n",
      "           Conv1d-61              [-1, 256, 28]          33,024\n",
      "      BatchNorm1d-62              [-1, 256, 28]             512\n",
      "             ReLU-63              [-1, 256, 28]               0\n",
      "    ResidualBlock-64              [-1, 256, 28]               0\n",
      "           Conv1d-65              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-66              [-1, 256, 28]             512\n",
      "             ReLU-67              [-1, 256, 28]               0\n",
      "           Conv1d-68              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-69              [-1, 256, 28]             512\n",
      "             ReLU-70              [-1, 256, 28]               0\n",
      "    ResidualBlock-71              [-1, 256, 28]               0\n",
      "           Conv1d-72              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-73              [-1, 256, 28]             512\n",
      "             ReLU-74              [-1, 256, 28]               0\n",
      "           Conv1d-75              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-76              [-1, 256, 28]             512\n",
      "             ReLU-77              [-1, 256, 28]               0\n",
      "    ResidualBlock-78              [-1, 256, 28]               0\n",
      "           Conv1d-79              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-80              [-1, 256, 28]             512\n",
      "             ReLU-81              [-1, 256, 28]               0\n",
      "           Conv1d-82              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-83              [-1, 256, 28]             512\n",
      "             ReLU-84              [-1, 256, 28]               0\n",
      "    ResidualBlock-85              [-1, 256, 28]               0\n",
      "           Conv1d-86              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-87              [-1, 256, 28]             512\n",
      "             ReLU-88              [-1, 256, 28]               0\n",
      "           Conv1d-89              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-90              [-1, 256, 28]             512\n",
      "             ReLU-91              [-1, 256, 28]               0\n",
      "    ResidualBlock-92              [-1, 256, 28]               0\n",
      "           Conv1d-93              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-94              [-1, 256, 28]             512\n",
      "             ReLU-95              [-1, 256, 28]               0\n",
      "           Conv1d-96              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-97              [-1, 256, 28]             512\n",
      "             ReLU-98              [-1, 256, 28]               0\n",
      "    ResidualBlock-99              [-1, 256, 28]               0\n",
      "          Conv1d-100              [-1, 512, 14]         393,728\n",
      "     BatchNorm1d-101              [-1, 512, 14]           1,024\n",
      "            ReLU-102              [-1, 512, 14]               0\n",
      "          Conv1d-103              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-104              [-1, 512, 14]           1,024\n",
      "          Conv1d-105              [-1, 512, 14]         131,584\n",
      "     BatchNorm1d-106              [-1, 512, 14]           1,024\n",
      "            ReLU-107              [-1, 512, 14]               0\n",
      "   ResidualBlock-108              [-1, 512, 14]               0\n",
      "          Conv1d-109              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-110              [-1, 512, 14]           1,024\n",
      "            ReLU-111              [-1, 512, 14]               0\n",
      "          Conv1d-112              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-113              [-1, 512, 14]           1,024\n",
      "            ReLU-114              [-1, 512, 14]               0\n",
      "   ResidualBlock-115              [-1, 512, 14]               0\n",
      "          Conv1d-116              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-117              [-1, 512, 14]           1,024\n",
      "            ReLU-118              [-1, 512, 14]               0\n",
      "          Conv1d-119              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-120              [-1, 512, 14]           1,024\n",
      "            ReLU-121              [-1, 512, 14]               0\n",
      "   ResidualBlock-122              [-1, 512, 14]               0\n",
      "  ResidualLayers-123              [-1, 512, 14]               0\n",
      "       AvgPool1d-124               [-1, 512, 1]               0\n",
      "          Linear-125                  [-1, 512]         262,656\n",
      "            ReLU-126                  [-1, 512]               0\n",
      "          Linear-127                    [-1, 1]             513\n",
      "     FinalLayers-128                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 7,491,265\n",
      "Trainable params: 7,491,265\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 6.68\n",
      "Params size (MB): 28.58\n",
      "Estimated Total Size (MB): 35.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# torchsummary may not work for your model\n",
    "summary(model, (4, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72265530-766d-4e96-aa71-3dc572607759",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = lossFunctions[0]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffdbe38-92e4-4f3b-95c7-50cc192465df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 92160 sequences, time: 8.828070402145386s, train Loss: 3.1123338646358913, train mse 3.1123338487413195, train pearson: 0.6662337454961247, train_spearman: 0.6820760031011348, val Loss: 3.0073201656341553, val mse: 3.007320022583008, val pearson: 0.6787708088781681, val spearman: 0.6938471647957187\n",
      "Epoch 2, 92160 sequences, time: 8.974015235900879s, train Loss: 2.985418004459805, train mse 2.985418023003472, train pearson: 0.6828709163824257, train_spearman: 0.6977301181554028, val Loss: 2.9682958364486693, val mse: 2.9682960510253906, val pearson: 0.6890987312567575, val spearman: 0.7044407691025286\n",
      "Epoch 3, 92160 sequences, time: 8.79938530921936s, train Loss: 2.9942171732584635, train mse 2.994216579861111, train pearson: 0.68404725313188, train_spearman: 0.6997012274911651, val Loss: 2.979528522491455, val mse: 2.9795284271240234, val pearson: 0.6900608283058259, val spearman: 0.7028745819875751\n",
      "Epoch 4, 92160 sequences, time: 8.828262090682983s, train Loss: 2.942710812886556, train mse 2.942710706922743, train pearson: 0.6873261345165078, train_spearman: 0.7023231519791979, val Loss: 3.500719976425171, val mse: 3.50072021484375, val pearson: 0.6816966785498255, val spearman: 0.7007070307553065\n",
      "Epoch 5, 92160 sequences, time: 8.799004077911377s, train Loss: 2.9477818171183268, train mse 2.947781711154514, train pearson: 0.6886736640237245, train_spearman: 0.7037466070570692, val Loss: 3.0029078245162966, val mse: 3.002907943725586, val pearson: 0.6788385471149934, val spearman: 0.6957930592215891\n",
      "Epoch 6, 92160 sequences, time: 8.851436853408813s, train Loss: 2.9538619226879543, train mse 2.9538621690538194, train pearson: 0.6887075167174512, train_spearman: 0.704029418171613, val Loss: 3.5752180099487303, val mse: 3.5752178192138673, val pearson: 0.6792333254229478, val spearman: 0.6967769672926135\n",
      "Epoch 7, 92160 sequences, time: 8.68242883682251s, train Loss: 2.9471986055374146, train mse 2.9471988254123263, train pearson: 0.6888183129063905, train_spearman: 0.7033247084196104, val Loss: 3.038484287261963, val mse: 3.0384843826293944, val pearson: 0.6819964508597395, val spearman: 0.6955290082623676\n",
      "Epoch 8, 92160 sequences, time: 8.785166025161743s, train Loss: 2.911883322397868, train mse 2.911883544921875, train pearson: 0.6933040162617858, train_spearman: 0.7095816171872399, val Loss: 2.8708367347717285, val mse: 2.8708368301391602, val pearson: 0.6900104295413664, val spearman: 0.7093936305166871\n",
      "Epoch 9, 92160 sequences, time: 8.714437007904053s, train Loss: 2.874832934803433, train mse 2.874832492404514, train pearson: 0.6968745518719742, train_spearman: 0.712220013771471, val Loss: 3.113969159126282, val mse: 3.1139692306518554, val pearson: 0.6868113892336176, val spearman: 0.7057926307751321\n",
      "Epoch 10, 92160 sequences, time: 8.91158676147461s, train Loss: 2.905230744679769, train mse 2.9052303738064236, train pearson: 0.6946113272126259, train_spearman: 0.7091089930178659, val Loss: 2.9249387979507446, val mse: 2.92493896484375, val pearson: 0.6957878825545782, val spearman: 0.7125007328490776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PrixFixeNet(\n",
       "  (l1): FirstLayers(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(4, 64, kernel_size=(7,), stride=(1,), padding=same)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (l2): ResidualLayers(\n",
       "    (layer0): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (4): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (l3): FinalLayers(\n",
       "    (avgpool): AvgPool1d(kernel_size=(14,), stride=(14,), padding=(0,))\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each combination will be assinged an ID to keep track of the combinations being tested.\n",
    "modelID = 0\n",
    "\n",
    "#train the model using this sample trainer function\n",
    "train(trainLoader, model, loss_fn, optimizer, scheduler, valLoader, 10, modelID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ff54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460f0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2])\n",
    "b = np.array([3,4])\n",
    "c = [a,b]\n",
    "d = np.array(c)\n",
    "print(d)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e8e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c4bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c4e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
