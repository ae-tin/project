{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19596439-7d04-4bb2-b535-23b4f660f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "from models.ResNet_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1c73d0-0761-41ed-89b9-782412b51146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "628a2f02-48ff-442c-b3e9-6ef926cb144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrixFixeNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        \n",
    "        super(PrixFixeNet, self).__init__()\n",
    "        self.l1 = layers[0]\n",
    "        self.l2 = layers[1]\n",
    "        self.l3 = layers[2]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        \n",
    "        if self.l2 is not None:\n",
    "            x = self.l2(x)\n",
    "        if self.l3 is not None:\n",
    "            x = self.l3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2110d8d7-7e07-4a61-b882-3f959feef281",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1s = [FirstLayers(4, 64, 7, 1, 'same')]\n",
    "l2s = [ResidualLayers(ResidualBlock, [3,4,6,3])]\n",
    "l3s = [FinalLayers(14, 512, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac87be5-ad4c-44d5-917b-1adf14e82810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 110]           1,856\n",
      "       BatchNorm1d-2              [-1, 64, 110]             128\n",
      "              ReLU-3              [-1, 64, 110]               0\n",
      "       FirstLayers-4              [-1, 64, 110]               0\n",
      "            Conv1d-5              [-1, 64, 110]          12,352\n",
      "       BatchNorm1d-6              [-1, 64, 110]             128\n",
      "              ReLU-7              [-1, 64, 110]               0\n",
      "            Conv1d-8              [-1, 64, 110]          12,352\n",
      "       BatchNorm1d-9              [-1, 64, 110]             128\n",
      "             ReLU-10              [-1, 64, 110]               0\n",
      "    ResidualBlock-11              [-1, 64, 110]               0\n",
      "           Conv1d-12              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-13              [-1, 64, 110]             128\n",
      "             ReLU-14              [-1, 64, 110]               0\n",
      "           Conv1d-15              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-16              [-1, 64, 110]             128\n",
      "             ReLU-17              [-1, 64, 110]               0\n",
      "    ResidualBlock-18              [-1, 64, 110]               0\n",
      "           Conv1d-19              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-20              [-1, 64, 110]             128\n",
      "             ReLU-21              [-1, 64, 110]               0\n",
      "           Conv1d-22              [-1, 64, 110]          12,352\n",
      "      BatchNorm1d-23              [-1, 64, 110]             128\n",
      "             ReLU-24              [-1, 64, 110]               0\n",
      "    ResidualBlock-25              [-1, 64, 110]               0\n",
      "           Conv1d-26              [-1, 128, 55]          24,704\n",
      "      BatchNorm1d-27              [-1, 128, 55]             256\n",
      "             ReLU-28              [-1, 128, 55]               0\n",
      "           Conv1d-29              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-30              [-1, 128, 55]             256\n",
      "           Conv1d-31              [-1, 128, 55]           8,320\n",
      "      BatchNorm1d-32              [-1, 128, 55]             256\n",
      "             ReLU-33              [-1, 128, 55]               0\n",
      "    ResidualBlock-34              [-1, 128, 55]               0\n",
      "           Conv1d-35              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-36              [-1, 128, 55]             256\n",
      "             ReLU-37              [-1, 128, 55]               0\n",
      "           Conv1d-38              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-39              [-1, 128, 55]             256\n",
      "             ReLU-40              [-1, 128, 55]               0\n",
      "    ResidualBlock-41              [-1, 128, 55]               0\n",
      "           Conv1d-42              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-43              [-1, 128, 55]             256\n",
      "             ReLU-44              [-1, 128, 55]               0\n",
      "           Conv1d-45              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-46              [-1, 128, 55]             256\n",
      "             ReLU-47              [-1, 128, 55]               0\n",
      "    ResidualBlock-48              [-1, 128, 55]               0\n",
      "           Conv1d-49              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-50              [-1, 128, 55]             256\n",
      "             ReLU-51              [-1, 128, 55]               0\n",
      "           Conv1d-52              [-1, 128, 55]          49,280\n",
      "      BatchNorm1d-53              [-1, 128, 55]             256\n",
      "             ReLU-54              [-1, 128, 55]               0\n",
      "    ResidualBlock-55              [-1, 128, 55]               0\n",
      "           Conv1d-56              [-1, 256, 28]          98,560\n",
      "      BatchNorm1d-57              [-1, 256, 28]             512\n",
      "             ReLU-58              [-1, 256, 28]               0\n",
      "           Conv1d-59              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-60              [-1, 256, 28]             512\n",
      "           Conv1d-61              [-1, 256, 28]          33,024\n",
      "      BatchNorm1d-62              [-1, 256, 28]             512\n",
      "             ReLU-63              [-1, 256, 28]               0\n",
      "    ResidualBlock-64              [-1, 256, 28]               0\n",
      "           Conv1d-65              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-66              [-1, 256, 28]             512\n",
      "             ReLU-67              [-1, 256, 28]               0\n",
      "           Conv1d-68              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-69              [-1, 256, 28]             512\n",
      "             ReLU-70              [-1, 256, 28]               0\n",
      "    ResidualBlock-71              [-1, 256, 28]               0\n",
      "           Conv1d-72              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-73              [-1, 256, 28]             512\n",
      "             ReLU-74              [-1, 256, 28]               0\n",
      "           Conv1d-75              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-76              [-1, 256, 28]             512\n",
      "             ReLU-77              [-1, 256, 28]               0\n",
      "    ResidualBlock-78              [-1, 256, 28]               0\n",
      "           Conv1d-79              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-80              [-1, 256, 28]             512\n",
      "             ReLU-81              [-1, 256, 28]               0\n",
      "           Conv1d-82              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-83              [-1, 256, 28]             512\n",
      "             ReLU-84              [-1, 256, 28]               0\n",
      "    ResidualBlock-85              [-1, 256, 28]               0\n",
      "           Conv1d-86              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-87              [-1, 256, 28]             512\n",
      "             ReLU-88              [-1, 256, 28]               0\n",
      "           Conv1d-89              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-90              [-1, 256, 28]             512\n",
      "             ReLU-91              [-1, 256, 28]               0\n",
      "    ResidualBlock-92              [-1, 256, 28]               0\n",
      "           Conv1d-93              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-94              [-1, 256, 28]             512\n",
      "             ReLU-95              [-1, 256, 28]               0\n",
      "           Conv1d-96              [-1, 256, 28]         196,864\n",
      "      BatchNorm1d-97              [-1, 256, 28]             512\n",
      "             ReLU-98              [-1, 256, 28]               0\n",
      "    ResidualBlock-99              [-1, 256, 28]               0\n",
      "          Conv1d-100              [-1, 512, 14]         393,728\n",
      "     BatchNorm1d-101              [-1, 512, 14]           1,024\n",
      "            ReLU-102              [-1, 512, 14]               0\n",
      "          Conv1d-103              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-104              [-1, 512, 14]           1,024\n",
      "          Conv1d-105              [-1, 512, 14]         131,584\n",
      "     BatchNorm1d-106              [-1, 512, 14]           1,024\n",
      "            ReLU-107              [-1, 512, 14]               0\n",
      "   ResidualBlock-108              [-1, 512, 14]               0\n",
      "          Conv1d-109              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-110              [-1, 512, 14]           1,024\n",
      "            ReLU-111              [-1, 512, 14]               0\n",
      "          Conv1d-112              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-113              [-1, 512, 14]           1,024\n",
      "            ReLU-114              [-1, 512, 14]               0\n",
      "   ResidualBlock-115              [-1, 512, 14]               0\n",
      "          Conv1d-116              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-117              [-1, 512, 14]           1,024\n",
      "            ReLU-118              [-1, 512, 14]               0\n",
      "          Conv1d-119              [-1, 512, 14]         786,944\n",
      "     BatchNorm1d-120              [-1, 512, 14]           1,024\n",
      "            ReLU-121              [-1, 512, 14]               0\n",
      "   ResidualBlock-122              [-1, 512, 14]               0\n",
      "  ResidualLayers-123              [-1, 512, 14]               0\n",
      "       AvgPool1d-124               [-1, 512, 1]               0\n",
      "          Linear-125                  [-1, 512]         262,656\n",
      "            ReLU-126                  [-1, 512]               0\n",
      "          Linear-127                    [-1, 1]             513\n",
      "     FinalLayers-128                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 7,491,265\n",
      "Trainable params: 7,491,265\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 6.68\n",
      "Params size (MB): 28.58\n",
      "Estimated Total Size (MB): 35.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "layers = [l1s[0], l2s[0], l3s[0]]\n",
    "\n",
    "while len(layers) != 10:\n",
    "    layers.append(None)\n",
    "\n",
    "currentPrixFixeModel = PrixFixeNet(layers).to(device)\n",
    "summary(currentPrixFixeModel, (4,110))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
