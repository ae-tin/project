{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0jDe-m_5aq4"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH9oF2RleEYl"
   },
   "source": [
    "## Load Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XamZpd5EeGHR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import session_info\n",
    "import pdb\n",
    "from sklearn.metrics import r2_score\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from Bio.Seq import Seq\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import socket\n",
    "import time\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import random as python_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "w9lA5-iVI0d6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "import math\n",
    "import pickle as pk\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl2lXOAv9ljx"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "D0pjVLfcfMl7"
   },
   "outputs": [],
   "source": [
    "RUNTIME = 'none'\n",
    "ARGS = {\n",
    "  'model_id' : 'm20220727e',\n",
    "  'global_seed' : 123,\n",
    "  'shuffle_size' : 1000,\n",
    "  'max_width' : 100,\n",
    "  'head_len' : 17,\n",
    "  'tail_len' : 13,\n",
    "  'pct_ds' : 1, # % of total data for training/testing,\n",
    "  'train_split' : 0.95,\n",
    "  'alphabets' : {'A' : 0, 'C' : 1, 'G' : 2, 'T' : 3, 'N' : 4, 'M' : 5},\n",
    "  'initial_lr' : 1e-15,\n",
    "  'max_lr' : 3e-4,\n",
    "  'initial_epoch': 0,\n",
    "  'epochs' : 20,\n",
    "  'batch_size' : 2,\n",
    "  'dropout_rate' : 0.1,\n",
    "  'kmer': 10,\n",
    "  'strides' : 1,\n",
    "  'embedding_dim' : 512,\n",
    "  'num_heads' : 8,\n",
    "  'ff_mult' : 4,\n",
    "  'num_projectors' : 32,\n",
    "  'n_blocks_regressor' : 4,\n",
    "  'warmup_steps' : 12500, # ~ 1 epoch\n",
    "  'mask_ratio' : 0.05,\n",
    "  'remote_sample_submission_file' : 'https://raw.githubusercontent.com/de-Boer-Lab/DREAM-2022/main/sample_submission.json',\n",
    "  'eval' : False,\n",
    "  'device':'cuda:1'\n",
    "}\n",
    "if RUNTIME == 'msi':\n",
    "  ARGS['remote_data_dir'] = 'https://s3.msi.umn.edu/gongx030/projects/dream_PGE/training_data/pct_ds=' + str(ARGS['pct_ds']) + '/'\n",
    "  ARGS['local_data_dir'] = re.sub('https://', './', ARGS['remote_data_dir'])\n",
    "  ARGS['remote_checkpoint_dir'] = 'https://s3.msi.umn.edu/gongx030/projects/dream_PGE/notebooks_msi/' + ARGS['model_id'] + '/tf_ckpts/'\n",
    "  ARGS['remote_log_dir'] = 'https://s3.msi.umn.edu/gongx030/projects/dream_PGE/notebooks_msi/' + ARGS['model_id'] + '/log/'\n",
    "  ARGS['local_checkpoint_dir'] = re.sub('https://', './', ARGS['remote_checkpoint_dir'])\n",
    "  ARGS['local_log_dir'] = re.sub('https://', './', ARGS['remote_log_dir'])\n",
    "  ARGS['remote_test_data'] = 'https://s3.msi.umn.edu/gongx030/projects/dream_PGE/test_sequences.txt.gz'\n",
    "  ARGS['local_test_data'] = re.sub('https://', './', ARGS['remote_test_data'])\n",
    "  ARGS['local_sample_submission_file'] = re.sub('https://', './', ARGS['remote_sample_submission_file'])\n",
    "  ARGS['remote_prediction_file'] = 'https://s3.msi.umn.edu/gongx030/projects/dream_PGE/predictions/' + ARGS['model_id'] + '/pred.json'\n",
    "  ARGS['local_prediction_file'] = re.sub('https://', './', ARGS['remote_prediction_file'])\n",
    "  ARGS['s3_prediction_file'] = re.sub('https://s3.msi.umn.edu', 's3://', ARGS['remote_prediction_file'])\n",
    "  ARGS['remote_prediction_tsv_file'] = 'https://s3.msi.umn.edu/gongx030/projects/dream_PGE/predictions/' + ARGS['model_id'] + '/pred.tsv'\n",
    "  ARGS['local_prediction_tsv_file'] = re.sub('https://', './', ARGS['remote_prediction_tsv_file'])\n",
    "  ARGS['s3_prediction_tsv_file'] = re.sub('https://s3.msi.umn.edu', 's3://', ARGS['remote_prediction_tsv_file'])\n",
    "else:\n",
    "  ARGS['local_data_dir'] = '/content/drive/MyDrive/training_data/pct_ds=' + str(ARGS['pct_ds']) + '/'\n",
    "  ARGS['local_checkpoint_dir'] = '/content/drive/MyDrive/' + ARGS['model_id'] + '/tf_ckpts/'\n",
    "  ARGS['local_log_dir'] = '/content/drive/MyDrive/' + ARGS['model_id'] + '/log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS['local_data_dir'] = '/Data1/PGE/torch_ti/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ZhZvwWifIpzY"
   },
   "outputs": [],
   "source": [
    "with open(ARGS['local_data_dir']+\"data.pk\",\"rb\") as fr:\n",
    "    data = pk.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i5XrE1H2Iwq"
   },
   "source": [
    "### Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5LTFxNSIWQID"
   },
   "outputs": [],
   "source": [
    "np.random.seed(ARGS['global_seed'])\n",
    "torch.manual_seed(ARGS['global_seed'])\n",
    "python_random.seed(ARGS['global_seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPZLHuW06Tcm"
   },
   "source": [
    "### pearson_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "bDou1j1A6S2j"
   },
   "outputs": [],
   "source": [
    "def pearson_r(x, y):\n",
    "    x = torch.tensor(x,dtype=torch.float32)\n",
    "    y = torch.tensor(y,dtype=torch.float32)\n",
    "    mx = torch.mean(x, axis = 0, keepdims = True)\n",
    "    my = torch.mean(y, axis = 0, keepdims = True)\n",
    "    xm = x - mx\n",
    "    ym = y - my\n",
    "    t1_norm = F.normalize(xm, p=2, dim=0)\n",
    "    t2_norm = F.normalize(ym, p=2, dim=0)\n",
    "    return torch.sum(torch.mul(t1_norm, t2_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4E4kvC_v6oYG",
    "outputId": "53ce49be-7138-490b-ba8f-85a92dc3592e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson r (stats.pearsonr): -0.09270195576139686\n",
      "pearson r (pearson_r): -0.09270194172859192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9819/2976460682.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x,dtype=torch.float32)\n",
      "/tmp/ipykernel_9819/2976460682.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100)\n",
    "y = np.random.rand(100)\n",
    "print('pearson r (stats.pearsonr): {}'.format(stats.pearsonr(x, y)[0]))\n",
    "print('pearson r (pearson_r): {}'.format(pearson_r(torch.unsqueeze(torch.Tensor(x),1), torch.unsqueeze(torch.Tensor(y),1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrQ9T4-oSk8X"
   },
   "source": [
    "### GLULayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "oMX5LC1aSkRK"
   },
   "outputs": [],
   "source": [
    "class GLULayer(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(GLULayer, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out,gate = torch.chunk(x, 2, dim = self.dim)\n",
    "        return out * self.sig(gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivpHjDlQSxUU",
    "outputId": "6f85a037-81fc-4924-cbb0-074aa9e0d808"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = GLULayer(dim = 1)\n",
    "x = torch.randn(3,6,10)\n",
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHdNKhzVvsMf"
   },
   "source": [
    "### SwiGLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "WeSyNETvvuex"
   },
   "outputs": [],
   "source": [
    "\n",
    "class SwiGLULayer(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(SwiGLULayer, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.swish = nn.SiLU() # same as swish\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, gate = torch.chunk(x, 2, dim = self.dim)\n",
    "        return out * self.swish(gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuwI-YXjvuex",
    "outputId": "7e3be8c3-6e7a-4886-d85d-26c9c763b953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = SwiGLULayer(dim = 1)\n",
    "x = torch.randn(3,6,10)\n",
    "layer(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7BVgkw-w4UO"
   },
   "source": [
    "### FeedForwardSwiGLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "eVdwwIxbw4UP"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeedForwardSwiGLU(nn.Module):\n",
    "    def __init__(self, embedding_dim, mult=4, rate = 0.0, use_bias = False):\n",
    "        super(FeedForwardSwiGLU, self).__init__()\n",
    "        swiglu_out = int(embedding_dim * mult/2)\n",
    "        self.layernorm = nn.LayerNorm(embedding_dim,eps = 1e-6)\n",
    "        self.linear1 = nn.Linear(embedding_dim,embedding_dim * mult, bias = use_bias)\n",
    "        self.swiglulayer = SwiGLULayer(dim = 1)\n",
    "        self.drop = nn.Dropout(rate)\n",
    "        self.linear2 = nn.Linear(swiglu_out,embedding_dim, bias = use_bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.layernorm(inputs.transpose(1,2)) # 차원바뀌고 채널 dim=2\n",
    "        x = self.linear1(x) \n",
    "        x = self.swiglulayer(x.transpose(1,2)) # 또 차원 바뀌고 채널 dim =1\n",
    "        x = self.drop(x)\n",
    "        x = self.linear2(x.transpose(1,2)) # 차원 바뀌고 채널 dim=2\n",
    "        out = self.drop(x.transpose(1,2)) # 차원 또 바뀌고 채널 dim =1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdHfQ6HHw4UP",
    "outputId": "966a8466-6c37-415f-cb16-2e13189dbb78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForwardSwiGLU(embedding_dim = 5, mult = 4)\n",
    "x = torch.randn(3,5,10)\n",
    "print(ffn(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rke3X-N6-n9S"
   },
   "source": [
    "### CustomSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "X73TEopBGYov"
   },
   "outputs": [],
   "source": [
    "n_train = 6400689\n",
    "model = FeedForwardSwiGLU(embedding_dim = 5, mult = 4)\n",
    "optim           = torch.optim.Adam(model.parameters(), lr = ARGS['initial_lr'], betas=(0.9, 0.98), eps=1e-08)\n",
    "scheduler       = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=ARGS['max_lr'],pct_start = 0.05, \n",
    "                                                                   steps_per_epoch=int(n_train/ARGS['batch_size'])+1, epochs=ARGS['epochs'],anneal_strategy='cos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "r-w_RbKWIXeM",
    "outputId": "b1995ed8-b95f-4da8-9b01-707fb00c2772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'OneCycleLR Scheduler')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs  = []\n",
    "for  i  in  range(250000):\n",
    "\tscheduler.step()\n",
    "\tlrs.append(optim.param_groups[0][\"lr\"])  \n",
    "\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"OneCycleLR Scheduler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGqeHeQRxxLY"
   },
   "source": [
    "### ConformerSASwiGLULayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "saxlznhLxxLY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ConformerSASwiGLULayer(nn.Module):\n",
    "    def __init__(self, embedding_dim,  ff_mult = 4, kernel_size = 15, rate = 0.2, num_heads = 4, use_bias = False):\n",
    "        super(ConformerSASwiGLULayer, self).__init__()\n",
    "        self.ff1 = FeedForwardSwiGLU(embedding_dim = embedding_dim, mult = ff_mult, rate = rate, use_bias = use_bias)\n",
    "        self.layernorm1 = nn.LayerNorm(embedding_dim,eps = 1e-6)\n",
    "        self.conv = nn.Sequential(   \n",
    "          nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=kernel_size, groups=embedding_dim, padding='same'),\n",
    "          nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=1, padding='same'),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(rate),\n",
    "        )\n",
    "        self.layernorm2 = nn.LayerNorm(embedding_dim,eps = 1e-6)    \n",
    "        self.attn = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads,batch_first=True)\n",
    "        self.ff2 = FeedForwardSwiGLU(embedding_dim = embedding_dim, mult = ff_mult, rate = rate, use_bias = use_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = x + 0.5 * self.ff1(x)\n",
    "        x = self.layernorm1(x.transpose(1,2)) #채널 dim = 2\n",
    "        x = x + self.conv(x.transpose(1, 2)).transpose(1, 2) # output 채널 dim = 2\n",
    "        x = self.layernorm2(x)\n",
    "        x = x + self.attn(x, x, x)[0]\n",
    "        x = x.transpose(1,2) + 0.5 * self.ff2(x.transpose(1,2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5mMf8GPxxLZ",
    "outputId": "92e9877e-f3ac-49da-b3f5-325d74b60719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 10])\n"
     ]
    }
   ],
   "source": [
    "layer = ConformerSASwiGLULayer(embedding_dim = 16)\n",
    "x = torch.randn(3,16,10)\n",
    "print(layer(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKbk2vhOTgA5"
   },
   "source": [
    "### SequenceMaskLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q7WXIVfClKlE"
   },
   "outputs": [],
   "source": [
    "class SequenceMaskLayer(nn.Module):\n",
    "    def __init__(self, n_positions, ratio = 0.2):\n",
    "        super(SequenceMaskLayer, self).__init__()\n",
    "        self.ratio = ratio\n",
    "        self.n_positions = n_positions\n",
    "        self.N = 4\n",
    "        self.M = 5\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.ratio > 0:\n",
    "            m = torch.rand(x.shape) < self.ratio\n",
    "            m = m*1\n",
    "            is_valid = x == self.N\n",
    "            is_valid = is_valid * 1\n",
    "            m = m * is_valid\n",
    "            x0 = torch.ones(x.shape) * self.M\n",
    "\n",
    "            x = m * x0 + (1 - m) * x\n",
    "            m = m.float()\n",
    "        else:\n",
    "            m = torch.zeros(x.shape)\n",
    "    \n",
    "        return x, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOj2tUQmTgA6",
    "outputId": "8a271106-304b-4b95-83a1-232664591280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 0., 0., 0., 4., 4., 1., 0., 4., 1., 0., 2., 1., 1., 0., 4., 2., 0.,\n",
      "         0., 3.],\n",
      "        [0., 2., 2., 3., 3., 0., 1., 3., 1., 3., 4., 2., 1., 5., 5., 1., 1., 0.,\n",
      "         2., 3.],\n",
      "        [2., 1., 1., 1., 3., 1., 0., 1., 4., 3., 3., 2., 3., 4., 0., 4., 2., 1.,\n",
      "         0., 2.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "layer = SequenceMaskLayer(n_positions = 20, ratio = 0.2)\n",
    "x = torch.rand([3,20])*5\n",
    "x = torch.floor(x)\n",
    "x, m = layer(x)\n",
    "print(x)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGFLv3peCCKS"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "om_YoxPICCKS"
   },
   "outputs": [],
   "source": [
    "input_dim = int(6) # A,C,G,T,N,M\n",
    "#input_dim = int(5) # A,C,G,T,N\n",
    "n_positions = ARGS['max_width'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbU-MCtK1B7k",
    "outputId": "3129bc87-a86a-49c5-b203-fa4af6e201ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampled dataset size: 6737568\n",
      "training dataset size: 6400689\n"
     ]
    }
   ],
   "source": [
    "n = int(len(data['seq']))\n",
    "n_train = int(n * ARGS['train_split'])\n",
    "print('downsampled dataset size: %d' % (n))\n",
    "print('training dataset size: %d' % (n_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQBqfMrpCCKT",
    "outputId": "51b10fec-522a-42f8-d692-4fa9e8eb19b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training samples: 6400689\n",
      "# val samples: 336879\n"
     ]
    }
   ],
   "source": [
    "train_data = {'seq':data['seq'][:n_train],'expression':data['expression'][:n_train]}\n",
    "val_data = {'seq':data['seq'][n_train:],'expression':data['expression'][n_train:]}\n",
    "\n",
    "print('# training samples: %d' % (len(train_data['seq'])))\n",
    "print('# val samples: %d' % (len(val_data['seq'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2xtZGxPzz4s"
   },
   "source": [
    "# DataLoader & TestSet Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "O5LDHmegztZL"
   },
   "outputs": [],
   "source": [
    "class train_loader(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data['seq']\n",
    "        self.data_label = data['expression']\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return torch.FloatTensor(self.data[index]), self.data_label[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class test_loader(object):\n",
    "    def __init__(self,args):\n",
    "        lines = open(\"/Data1/PGE/torch_ti/filtered_test_data_with_MAUDE_expression.txt\", \"r\").read().splitlines()\n",
    "        data = [x.split('\\t')[0] for x in lines]\n",
    "        data_label = [x.split('\\t')[1] for x in lines]\n",
    "        df = pd.DataFrame()\n",
    "        df['dna'] = data\n",
    "        df['expression'] = data_label\n",
    "        df['dna'] = df['dna'].astype('string')\n",
    "        df['len'] = df['dna'].str.len()\n",
    "        print('number of unique sequences in the first {} positions: {}'.format(args['head_len'], len(df['dna'].str[:args['head_len']].unique())))\n",
    "        print('number of unique sequences in the last {} positions: {}'.format(args['tail_len'], len(df['dna'].str[-args['tail_len']:].unique())))\n",
    "        df['dna'] = df['dna'].str[args['head_len']:]\n",
    "        df['dna'] = df['dna'].str[:-args['tail_len']]\n",
    "        df['len'] = df['dna'].str.len()\n",
    "        assert all(df['len'] <= args['max_width'])\n",
    "        \n",
    "        df['dna'] = df['dna'].str.pad(width = args['max_width'], side = 'both', fillchar = 'N')\n",
    "        df['dna'] = df['dna'] + df['dna'].apply(lambda x: str(Seq(x).reverse_complement())).astype('string')\n",
    "        \n",
    "        input_dim = int(6) # A,C,G,T,N,M\n",
    "        n_positions = int(args['max_width'] * 2)\n",
    "        self.dna = np.empty((0, n_positions), np.uint8)\n",
    "        for x in np.array_split(df['dna'], 10): # split data into chunks\n",
    "            y = np.array(x.apply(list))\n",
    "            y = np.vstack(y)\n",
    "            y = np.vectorize(ARGS['alphabets'].get)(y)\n",
    "            y = y.astype(np.uint8)\n",
    "            print(y.shape)\n",
    "            self.dna = np.append(self.dna, y, axis = 0)\n",
    "        print(self.dna.shape)\n",
    "        self.expression = df['expression'].astype('float32').to_numpy()\n",
    "        expression_std = np.std(self.expression)\n",
    "        expression_mean = np.mean(self.expression)\n",
    "        self.expression = (self.expression - expression_mean) / expression_std\n",
    "        \n",
    "        print(self.expression.shape)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return torch.FloatTensor(self.dna[index]), self.expression[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KwOLqNOwU3U"
   },
   "source": [
    "## The regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstLayer_Block(nn.Module):\n",
    "    def __init__(self, n_positions, kmer = 3, embedding_dim = 32, input_dim = 5, strides = 2, ratio = 0.2, ff_mult = 4, use_bias = False, num_projectors = 8):\n",
    "        super(FirstLayer_Block, self).__init__()\n",
    "        self.n_positions = int(n_positions / strides)\n",
    "        self.input_dim = input_dim\n",
    "        self.kmer = kmer\n",
    "        self.strides = strides\n",
    "        self.num_projectors = num_projectors\n",
    "        \n",
    "        self.masking = SequenceMaskLayer(n_positions = n_positions, ratio = ratio)\n",
    "        self.pos_embedding = nn.Embedding(self.n_positions, embedding_dim)\n",
    "        self.strand_embedding = nn.Embedding(2, embedding_dim) # plus/minus strands\n",
    "        self.expression_embedding = nn.Linear(1,embedding_dim)\n",
    "        self.kmer_dense = nn.Linear(input_dim*self.kmer,embedding_dim)\n",
    "       \n",
    "\n",
    "\n",
    "    def forward(self, x): # input = (batch, seq)\n",
    "        print('input_shape : ',x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = F.one_hot(x.to(torch.int64), self.input_dim)   # output = (b,seq,embed)\n",
    "\n",
    "        x = x.unsqueeze(2)  # b,seq,em,1\n",
    "        x_shape = x.shape\n",
    "        fold_shape = x.unfold(1,self.kmer,self.strides).transpose(3,4).shape\n",
    "        div = x_shape[1] - fold_shape[1]\n",
    "        x = F.pad(x.unfold(1,self.kmer,self.strides).transpose(3,4),(0,0,0,0,0,0,0,div),'constant',0).reshape(x.shape[0],x.shape[1]//self.strides,x.shape[2],-1)\n",
    "        x = x.squeeze(2).float()\n",
    "        print('unfold shape : ',x.shape)\n",
    "        x = self.kmer_dense(x)\n",
    "\n",
    "        pos = torch.arange(start=0, end = self.n_positions, step=1).cuda()\n",
    "        pos = pos.unsqueeze(0)\n",
    "        pos = self.pos_embedding(pos.long())\n",
    "\n",
    "        strand = torch.tensor(np.repeat([0,1], repeats = int(self.n_positions / 2))).cuda()\n",
    "        strand = strand.unsqueeze(0)\n",
    "        strand = self.strand_embedding(strand.long())\n",
    "\n",
    "        x = x + pos + strand  # 채널 dim=2\n",
    "\n",
    "        expression = torch.zeros((batch_size, self.num_projectors, 1)).cuda()\n",
    "        expression = self.expression_embedding(expression.float())\n",
    "\n",
    "        x = torch.cat([expression, x], dim = 1)\n",
    "        x = x.transpose(1,2)\n",
    "        print('first_output_shape : ',x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Core_Block(nn.Module):\n",
    "    def __init__(self, embedding_dim = 32, input_dim = 5, n_blocks = 4, \n",
    "               kernel_size =15, rate = 0.2, num_heads = 4):\n",
    "        super(Core_Block, self).__init__()\n",
    "        self.n_blocks = n_blocks\n",
    "        self.blocks = nn.ModuleList([ConformerSASwiGLULayer(embedding_dim = embedding_dim,\n",
    "                                    kernel_size = kernel_size, rate = rate, num_heads = num_heads) for _ in range(n_blocks)])\n",
    "\n",
    "    def forward(self, x): \n",
    "        print('core_input_shape : ',x.shape)\n",
    "        for i in range(self.n_blocks) :\n",
    "            x = self.blocks[i](x)\n",
    "        print('core_output_shape : ',x.transpose(1,2).shape)\n",
    "        return x.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalLayer_Block(nn.Module):\n",
    "    def __init__(self, n_positions, embedding_dim = 32, input_dim = 5, rate = 0.2, strides = 2, use_bias = False, num_projectors = 8):\n",
    "        super(FinalLayer_Block, self).__init__()\n",
    "        \n",
    "        self.n_positions = int(n_positions / strides)\n",
    "        self.num_projectors = num_projectors\n",
    "        \n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        self.expression_dense = nn.Linear(embedding_dim,1)\n",
    "        self.nucleotide_dense = nn.Linear(embedding_dim,input_dim)\n",
    "\n",
    "    def forward(self, x): \n",
    "        print('final_input_shape : ',x.shape)\n",
    "        expression = x[:,:self.num_projectors,:]\n",
    "        x = x[:, -self.n_positions:, :]\n",
    "\n",
    "        expression = self.dropout(expression)\n",
    "        expression = self.expression_dense(expression)\n",
    "        expression = torch.mean(expression, 1)\n",
    "\n",
    "        x = self.nucleotide_dense(x)\n",
    "        print('final_seq_reproduce_shape : ',x.transpose(1,2).shape)\n",
    "        print('final_output_shape : ',expression.shape)\n",
    "        return expression, x.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self, n_positions, kmer = 3, embedding_dim = 32, input_dim = 5, n_blocks = 4, \n",
    "               kernel_size =15, rate = 0.2, strides = 2, ratio = 0.2, num_heads = 4, ff_mult = 4, \n",
    "               use_bias = False, num_projectors = 8):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        self.masking = SequenceMaskLayer(n_positions = n_positions, ratio = ratio)\n",
    "        \n",
    "        self.first_block = FirstLayer_Block(n_positions, kmer, embedding_dim, input_dim, strides, \n",
    "                                            ratio, ff_mult, use_bias, num_projectors)\n",
    "        self.core_block = Core_Block(embedding_dim, input_dim, n_blocks, \n",
    "                                     kernel_size, rate, num_heads)\n",
    "        self.final_block = FinalLayer_Block(n_positions, embedding_dim, input_dim, rate,\n",
    "                                       strides, use_bias, num_projectors)\n",
    "\n",
    "    def forward(self, x): # input = (batch, seq)\n",
    "\n",
    "        first_out = self.first_block(x)\n",
    "        core_out = self.core_block(first_out)\n",
    "        expression, seq_out = self.final_block(core_out)\n",
    "\n",
    "        return expression, seq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "z-jAAiPA0oMS"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class RegressorModel(nn.Module):\n",
    "\tdef __init__(self, args,**kwargs):\n",
    "\t\tsuper(RegressorModel, self).__init__()\n",
    "\t\t## regressor\n",
    "\t\tself.arg = args\n",
    "\t\tself.regressor = Regressor(n_positions = n_positions,embedding_dim = args['embedding_dim'],\n",
    "                             n_blocks = args['n_blocks_regressor'],kmer = args['kmer'],input_dim = input_dim,\n",
    "                             strides = args['strides'],ratio = args['mask_ratio'],num_heads = args['num_heads'],\n",
    "                             rate = args['dropout_rate'],num_projectors = args['num_projectors']).cuda()\n",
    "\t\tself.mse_loss = nn.MSELoss(reduction='none').cuda()\n",
    "\t\tself.scc_loss = nn.CrossEntropyLoss( reduction='none').cuda()\n",
    "\t\tself.optim           = torch.optim.Adam(self.regressor.parameters(), lr = args['initial_lr'], betas=(0.9, 0.98), eps=1e-08)\n",
    "\t\tself.scheduler       = torch.optim.lr_scheduler.OneCycleLR(self.optim, max_lr=args['max_lr'],pct_start = 0.05, \n",
    "                                                                   steps_per_epoch=int(n_train/args['batch_size'])+1, epochs=args['epochs'],anneal_strategy='cos')\n",
    "\t\tprint(time.strftime(\"%m-%d %H:%M:%S\") + \" Model para number(백만) = %.2f\"%(sum(param.numel() for param in self.regressor.parameters()) / 1024 / 1024))\n",
    "\n",
    "\tdef train_network(self, epoch, loader):\n",
    "\t\tself.train()\n",
    "\t\t## Update the learning rate based on the current epoch\n",
    "\t\tif epoch > 0 :\n",
    "\t\t\tself.scheduler.step((epoch - 1)*int(n_train/self.arg['batch_size']))\n",
    "\t\t\tprint('LR : ',self.scheduler.get_last_lr()[0])\n",
    "\t\tindex, loss = 0, 0\n",
    "\t\tfor num, (data, labels) in tqdm(enumerate(loader, start = 1)):\n",
    "\n",
    "\t\t\tself.zero_grad()\n",
    "\t\t\tseq, mask = self.regressor.masking(data)\n",
    "\t\t\tlabels = labels.cuda()\n",
    "\t\t\texpression, seq_pred = self.regressor.forward(data.cuda()) \n",
    "\t\t\tloss_expression = self.mse_loss(labels.to(torch.float32), expression.squeeze(1).to(torch.float32))\n",
    "\t\t\tprint('data shape : ',data.shape)           \n",
    "\t\t\tprint('seq_pred shape : ',seq_pred.shape)\n",
    "\t\t\tprint('loss shape : ',self.scc_loss(seq_pred,data.long().cuda()).shape)\n",
    "\t\t\tprint('mask shape : ',mask.shape)\n",
    "\t\t\tloss_seq = mask.cuda() * self.scc_loss(seq_pred,data.long().cuda())\n",
    "\t\t\tloss_seq = torch.sum(loss_seq) / (torch.sum(mask.cuda()) + 1)\n",
    "\t\t\tnloss = (loss_expression.to(torch.float32) + loss_seq.to(torch.float32)).mean().to(torch.float32)\n",
    "\t\t\t\n",
    "\t\t\tnloss.backward()\n",
    "\t\t\tself.optim.step()\n",
    "\t\t\tself.scheduler.step()\n",
    "\t\t\tlr = self.scheduler.get_last_lr()[0]\n",
    "\t\t\tindex += len(labels)\n",
    "\t\t\tloss += nloss.detach().cpu().numpy()\n",
    "\t\t\tif num % 200 == 0 :\n",
    "\t\t\t\tsys.stderr.write(time.strftime(\"%m-%d %H:%M:%S\") + \\\n",
    "\t\t\t\t\" [%2d] Lr: %5f, Training: %.2f%%, \"    %(epoch, lr, 100 * (num / loader.__len__())) + \\\n",
    "\t\t\t\t\" Loss: %.5f \\r\"        %(loss/(num)))\n",
    "\t\t\t\tsys.stderr.flush()\n",
    "\t\t\t\tsys.stdout.write(\"\\n\")\n",
    "\n",
    "\t\treturn loss/num, lr \n",
    "\n",
    "\tdef eval_network(self, loader):\n",
    "\t\tself.eval()\n",
    "\t\texp = []\n",
    "\t\treal_exp = []\n",
    "\t\tfor idx, (data,labels) in tqdm(enumerate(loader)):\n",
    "\t\t\tdata_1 = torch.FloatTensor(data).cuda()\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\texpression, _ = self.regressor.forward(data_1)\n",
    "\t\t\tif len(expression.shape) > 1 :\n",
    "\t\t\t\texpression = expression.reshape(-1)\n",
    "\t\t\t\texpression = expression.detach().cpu().numpy()\n",
    "\t\t\t\tlabels = labels.detach().cpu().numpy() \n",
    "\t\t\texp.append(expression)\n",
    "\t\t\treal_exp.append(labels)\n",
    "\t\t\t\n",
    "\t\t# Coumpute Metric\n",
    "\t\texp = np.array(exp).reshape(-1)\n",
    "\t\treal_exp = np.array(real_exp).reshape(-1)\n",
    "\t\tPR = pearson_r(exp, real_exp)\n",
    "\n",
    "\t\treturn PR\n",
    "\n",
    "\tdef save_parameters(self, path):\n",
    "\t\ttorch.save(self.state_dict(), path)\n",
    "\n",
    "\tdef load_parameters(self, path):\n",
    "\t\tself_state = self.state_dict()\n",
    "\t\tloaded_state = torch.load(path)\n",
    "\t\tfor name, param in loaded_state.items():\n",
    "\t\t\torigname = name\n",
    "\t\t\tif name not in self_state:\n",
    "\t\t\t\tname = name.replace(\"module.\", \"\")\n",
    "\t\t\t\tif name not in self_state:\n",
    "\t\t\t\t\tprint(\"%s is not in the model.\"%origname)\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\tif self_state[name].size() != loaded_state[origname].size():\n",
    "\t\t\t\tprint(\"Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state[origname].size()))\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tself_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOtXgSxYvy0F"
   },
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGLEOzKhpPE2"
   },
   "source": [
    "### Epoch 1 \n",
    "\n",
    "initial epoch: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2VpPeGE-OeX-",
    "outputId": "0cf7da67-67f8-4b6d-b151-a0c481d9fcb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n",
      "Current cuda device: 1\n",
      "number of unique sequences in the first 17 positions: 1\n",
      "number of unique sequences in the last 13 positions: 1\n",
      "(7111, 200)\n",
      "(7111, 200)\n",
      "(7111, 200)\n",
      "(7110, 200)\n",
      "(7110, 200)\n",
      "(7110, 200)\n",
      "(7110, 200)\n",
      "(7110, 200)\n",
      "(7110, 200)\n",
      "(7110, 200)\n",
      "(71103, 200)\n",
      "(71103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-27 19:10:58 Model para number(백만) = 17.19\n",
      "LR :  1.200000000000002e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:01,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:01, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:01, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:01, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:02, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:02, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:02, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n",
      "input_shape :  torch.Size([2, 200])\n",
      "unfold shape :  torch.Size([2, 200, 60])\n",
      "first_output_shape :  torch.Size([2, 512, 232])\n",
      "core_input_shape :  torch.Size([2, 512, 232])\n",
      "core_output_shape :  torch.Size([2, 232, 512])\n",
      "final_input_shape :  torch.Size([2, 232, 512])\n",
      "final_seq_reproduce_shape :  torch.Size([2, 6, 200])\n",
      "final_output_shape :  torch.Size([2, 1])\n",
      "data shape :  torch.Size([2, 200])\n",
      "seq_pred shape :  torch.Size([2, 6, 200])\n",
      "loss shape :  torch.Size([2, 200])\n",
      "mask shape :  torch.Size([2, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:02,  8.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m score_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(score_save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     50\u001b[0m \t\u001b[38;5;66;03m## Training for one epoch\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \tloss, lr \u001b[38;5;241m=\u001b[39m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \t\u001b[38;5;66;03m## Evaluation every [test_step] epochs\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mRegressorModel.train_network\u001b[0;34m(self, epoch, loader)\u001b[0m\n\u001b[1;32m     38\u001b[0m loss_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(loss_seq) \u001b[38;5;241m/\u001b[39m (torch\u001b[38;5;241m.\u001b[39msum(mask\u001b[38;5;241m.\u001b[39mcuda()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m nloss \u001b[38;5;241m=\u001b[39m (loss_expression\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m+\u001b[39m loss_seq\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32))\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mnloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the main code of the ECAPATDNN project, to define the parameters and build the construction\n",
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "import argparse, glob, os, torch, warnings, time\n",
    "\n",
    "\n",
    "model_save_path = \"exps/model_reproducing_3module\"\n",
    "score_save_path = \"exps/score_reproducing_3module.txt\"\n",
    "os.makedirs(model_save_path,exist_ok = True)\n",
    "\n",
    "device = ARGS['device']\n",
    "torch.cuda.set_device(device)\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "\n",
    "\n",
    "## Define the data loader\n",
    "trainloader = train_loader(train_data)\n",
    "trainLoader = torch.utils.data.DataLoader(trainloader, batch_size = ARGS['batch_size'], shuffle = True, num_workers = 0, drop_last = True)\n",
    "valloader = train_loader(val_data)\n",
    "valLoader = torch.utils.data.DataLoader(valloader, batch_size = ARGS['batch_size'], shuffle = True, num_workers = 0, drop_last = True)\n",
    "testloader = test_loader(ARGS)\n",
    "testLoader = torch.utils.data.DataLoader(testloader, batch_size = ARGS['batch_size'], shuffle = True, num_workers = 0, drop_last = True)\n",
    "\n",
    "## Search for the exist models\n",
    "modelfiles = glob.glob('%s/model_0*.model'%model_save_path)\n",
    "modelfiles.sort()\n",
    "\n",
    "## Otherwise, system will try to start from the saved model&epoch\n",
    "if len(modelfiles) >= 1:\n",
    "\tprint(\"Model %s loaded from previous state!\"%modelfiles[-1])\n",
    "\tepoch = int(os.path.splitext(os.path.basename(modelfiles[-1]))[0][6:]) + 1\n",
    "\ts = RegressorModel(ARGS)\n",
    "\ts.load_parameters(modelfiles[-1])\n",
    "\teval_pr_ = s.eval_network(testLoader)\n",
    "\tprint('Previous Eval Pearson_R : ',eval_pr_)\n",
    "## Otherwise, system will train from scratch\n",
    "else:\n",
    "\tepoch = 1\n",
    "\ts = RegressorModel(ARGS)\n",
    "\n",
    "pr = []\n",
    "eval_pr = []\n",
    "score_file = open(score_save_path, \"a+\")\n",
    "\n",
    "while(1):\n",
    "\t## Training for one epoch\n",
    "\tloss, lr = s.train_network(epoch = epoch, loader = trainLoader)\n",
    "\n",
    "\t## Evaluation every [test_step] epochs\n",
    "\tif epoch % 1 == 0:\n",
    "\t\ts.save_parameters(model_save_path + \"/model_%04d.model\"%epoch)\n",
    "\t\tpr.append(s.eval_network(valLoader))\n",
    "\t\tprint(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%d epoch, Pearson_R %2.2f%%, bestPearson_R %2.2f%%\"%(epoch, pr[-1], max(pr)))\n",
    "\t\tscore_file.write(\"%d epoch, LR %f, LOSS %f, Pearson_R %2.2f%%, bestPearson_R %2.2f%%\\n\"%(epoch, lr, loss, pr[-1], max(pr)))\n",
    "\t\tscore_file.flush()\n",
    "\t\tif pr[-1] == max(pr) :\n",
    "\t\t\ts.save_parameters(model_save_path + \"/model_best.model\")\n",
    "\t\t\teval_pr.append(s.eval_network(testLoader))\n",
    "\t\t\tprint(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%d epoch, Eval_Pearson_R %2.2f%%, Best_Eval_Pearson_R %2.2f%%\"%(epoch, eval_pr[-1], max(eval_pr)))\n",
    "\t\t\tscore_file.write(\"%d epoch, LR %f, LOSS %f, Pearson_R %2.2f%%, Best_Eval_Pearson_R %2.2f%%\\n\"%(epoch, lr, loss, eval_pr[-1], max(eval_pr)))\n",
    "\t\t\tscore_file.flush()\n",
    "\n",
    "\tif epoch >= ARGS['epochs']:\n",
    "\t\tquit()\n",
    "\n",
    "\tepoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zp22H950YtNt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19E3HT1ESJ4A"
   },
   "source": [
    "## Session Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "53wVoagb4tD8",
    "outputId": "74fa0970-dc30-492f-9cc9-76ce90418ec9"
   },
   "outputs": [],
   "source": [
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFWCf4x-5bTE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
