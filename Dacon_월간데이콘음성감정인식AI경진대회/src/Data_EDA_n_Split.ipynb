{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dbfd99-d725-4f2e-9cbc-fb8710578b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.spatial import distance\n",
    "from textblob import TextBlob\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67ecc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import pickle as pk\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7fcbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display as dsp\n",
    "from IPython.display import Audio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3873a9e6-0884-4876-b015-bbcb5d4079f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "DATA_DIR = './data'\n",
    "PREPROC_DIR = './data'\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train_df['array'] = None\n",
    "train_df['transcription'] = None\n",
    "\n",
    "test_df['array'] = None\n",
    "test_df['transcription'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb29f57d-cd86-4251-bc2d-a1df850fd6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df):\n",
    "    df = df.copy()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    df = df.copy()\n",
    "    for idx, row in tqdm(df.iterrows(),total=len(df)):\n",
    "        path = row['path']\n",
    "        waveform, sample_rate = torchaudio.load(os.path.join(DATA_DIR, path))\n",
    "        waveform = torchaudio.functional.resample(waveform, orig_freq=sample_rate, new_freq=SAMPLE_RATE)\n",
    "        inputs = processor(waveform[0], sampling_rate=SAMPLE_RATE, return_tensors=\"pt\")\n",
    "        array = inputs['input_values'].cpu().numpy().tolist()[0]\n",
    "        df.at[idx,'array']=array\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs.to(device)).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)[0].lower()\n",
    "        transcription = ''.join(TextBlob(transcription).correct())\n",
    "        df.loc[idx,'transcription']=transcription\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1233b2b0-b757-4d30-adf8-0c92d3c9575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3c4b3c52c04903a59772ef345dab55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c1c2368770473d83a4e4ed47f4e9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbbfc4e8b4445f192a40761e5aac667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268aacd87098411595591e685116410c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041e48b59bfc41dd8926308ce94ee487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  tensor = as_tensor(value)\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9168a8fa0da846aeafae3168e5ebbe65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_preproc = preproc(train_df)\n",
    "test_df_preproc = preproc(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0062dfa-362b-483a-b65b-c6ec52ef40a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_preproc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_df_preproc\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df_preproc' is not defined"
     ]
    }
   ],
   "source": [
    "train_df_preproc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1e6c4eb-5871-4010-9c7c-083acfc3fcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>array</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>./test/TEST_0000.wav</td>\n",
       "      <td>[-0.11806084960699081, -0.10792392492294312, -...</td>\n",
       "      <td>i would like a new alarm lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>./test/TEST_0001.wav</td>\n",
       "      <td>[0.025349510833621025, 0.016926344484090805, 0...</td>\n",
       "      <td>maybe to morrow it will be called</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>./test/TEST_0002.wav</td>\n",
       "      <td>[0.0435451902449131, 0.0779065266251564, 0.016...</td>\n",
       "      <td>maybe to morrow it will be cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>./test/TEST_0003.wav</td>\n",
       "      <td>[0.1832374632358551, 0.11323649436235428, 0.13...</td>\n",
       "      <td>it's eleven o'clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>./test/TEST_0004.wav</td>\n",
       "      <td>[0.021504908800125122, 0.02967752143740654, 0....</td>\n",
       "      <td>don't forget a jacket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                  path  \\\n",
       "0  TEST_0000  ./test/TEST_0000.wav   \n",
       "1  TEST_0001  ./test/TEST_0001.wav   \n",
       "2  TEST_0002  ./test/TEST_0002.wav   \n",
       "3  TEST_0003  ./test/TEST_0003.wav   \n",
       "4  TEST_0004  ./test/TEST_0004.wav   \n",
       "\n",
       "                                               array  \\\n",
       "0  [-0.11806084960699081, -0.10792392492294312, -...   \n",
       "1  [0.025349510833621025, 0.016926344484090805, 0...   \n",
       "2  [0.0435451902449131, 0.0779065266251564, 0.016...   \n",
       "3  [0.1832374632358551, 0.11323649436235428, 0.13...   \n",
       "4  [0.021504908800125122, 0.02967752143740654, 0....   \n",
       "\n",
       "                       transcription  \n",
       "0      i would like a new alarm lost  \n",
       "1  maybe to morrow it will be called  \n",
       "2    maybe to morrow it will be cold  \n",
       "3                it's eleven o'clock  \n",
       "4              don't forget a jacket  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_preproc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b644eb90-1b4c-4c57-9086-634b513d8d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 최대 길이: 40\n",
      "test 최대 길이: 41\n"
     ]
    }
   ],
   "source": [
    "print(\"train 최대 길이:\", train_df_preproc['transcription'].map(len).max())\n",
    "print(\"test 최대 길이:\", test_df_preproc['transcription'].map(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3eea5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./train/TRAIN_0000.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./train/TRAIN_0001.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./train/TRAIN_0002.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./train/TRAIN_0003.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./train/TRAIN_0004.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                    path  label\n",
       "0  TRAIN_0000  ./train/TRAIN_0000.wav      1\n",
       "1  TRAIN_0001  ./train/TRAIN_0001.wav      2\n",
       "2  TRAIN_0002  ./train/TRAIN_0002.wav      4\n",
       "3  TRAIN_0003  ./train/TRAIN_0003.wav      5\n",
       "4  TRAIN_0004  ./train/TRAIN_0004.wav      4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef3a6a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    867\n",
       "1    848\n",
       "2    859\n",
       "3    852\n",
       "4    722\n",
       "5    853\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.groupby(train.label).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff8bcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.id.groupby(train.label).count().index\n",
    "Y = train.id.groupby(train.label).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1b9a835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(X, Y)\n",
    "plt.xticks(X)\n",
    "plt.title(\"Number of labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a2c1523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [02:35<00:00, 32.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "len_list = []\n",
    "\n",
    "for i in tqdm(train.id):\n",
    "    y, s = librosa.load('./data/train/' + i + '.wav')\n",
    "    len_list.append(len(y)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa3681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Length of audio'}, ylabel='Density'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Length of audio\")\n",
    "sns.distplot(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51740378",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/train/*.wav'\n",
    "test_path = './data/test/*.wav'\n",
    "train_list = glob(train_path)\n",
    "test_list = glob(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c916bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n",
      "1881\n"
     ]
    }
   ],
   "source": [
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55208c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3141cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bf0fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df_preproc.label\n",
    "train_features, val_features, train_targets, test_targets = train_test_split(\n",
    "        train_df_preproc, label,\n",
    "        train_size=0.8,\n",
    "        test_size=0.2,\n",
    "        # random but same for all run, also accurancy depends on the\n",
    "        # selection of data e.g. if we put 10 then accuracy will be 1.0\n",
    "        # in this example\n",
    "        random_state=23,\n",
    "        # keep same proportion of 'target' in test and target data\n",
    "        stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14ce2c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>array</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./train/TRAIN_0000.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1033457517623901, 1.2063554525375366, 1.166...</td>\n",
       "      <td>it's eleven o'clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./train/TRAIN_0001.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.5838981866836548, -0.6609091758728027, -0....</td>\n",
       "      <td>the surface is sleek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./train/TRAIN_0002.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.27893486618995667, 0.2514820098876953, 0.24...</td>\n",
       "      <td>we'll stop in a couple of minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./train/TRAIN_0004.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.16494052112102509, -0.15212097764015198, -...</td>\n",
       "      <td>donc will get a jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN_0005</td>\n",
       "      <td>./train/TRAIN_0005.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.10450570285320282, 0.07023542374372482, 0.0...</td>\n",
       "      <td>on my way to the meeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                    path  label  \\\n",
       "0  TRAIN_0000  ./train/TRAIN_0000.wav      1   \n",
       "1  TRAIN_0001  ./train/TRAIN_0001.wav      2   \n",
       "2  TRAIN_0002  ./train/TRAIN_0002.wav      4   \n",
       "4  TRAIN_0004  ./train/TRAIN_0004.wav      4   \n",
       "5  TRAIN_0005  ./train/TRAIN_0005.wav      3   \n",
       "\n",
       "                                               array  \\\n",
       "0  [1.1033457517623901, 1.2063554525375366, 1.166...   \n",
       "1  [-0.5838981866836548, -0.6609091758728027, -0....   \n",
       "2  [0.27893486618995667, 0.2514820098876953, 0.24...   \n",
       "4  [-0.16494052112102509, -0.15212097764015198, -...   \n",
       "5  [0.10450570285320282, 0.07023542374372482, 0.0...   \n",
       "\n",
       "                       transcription  \n",
       "0                it's eleven o'clock  \n",
       "1               the surface is sleek  \n",
       "2  we'll stop in a couple of minutes  \n",
       "4             donc will get a jacket  \n",
       "5           on my way to the meeting  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48f86c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>array</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./train/TRAIN_0003.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.20071503520011902, 0.20071503520011902, 0.2...</td>\n",
       "      <td>maybe to morrow it will be cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRAIN_0006</td>\n",
       "      <td>./train/TRAIN_0006.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.016541067510843277, -0.024171410128474236,...</td>\n",
       "      <td>don't forget jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRAIN_0009</td>\n",
       "      <td>./train/TRAIN_0009.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5918120741844177, -0.5142191648483276, -0....</td>\n",
       "      <td>i's began dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TRAIN_0014</td>\n",
       "      <td>./train/TRAIN_0014.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.20191602408885956, 0.17535044252872467, 0.1...</td>\n",
       "      <td>that is exactly what happened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TRAIN_0018</td>\n",
       "      <td>./train/TRAIN_0018.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.4908468425273895, -0.40923216938972473, -0...</td>\n",
       "      <td>i wonder what this is about</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                    path  label  \\\n",
       "3   TRAIN_0003  ./train/TRAIN_0003.wav      5   \n",
       "6   TRAIN_0006  ./train/TRAIN_0006.wav      0   \n",
       "9   TRAIN_0009  ./train/TRAIN_0009.wav      1   \n",
       "14  TRAIN_0014  ./train/TRAIN_0014.wav      4   \n",
       "18  TRAIN_0018  ./train/TRAIN_0018.wav      4   \n",
       "\n",
       "                                                array  \\\n",
       "3   [0.20071503520011902, 0.20071503520011902, 0.2...   \n",
       "6   [-0.016541067510843277, -0.024171410128474236,...   \n",
       "9   [-0.5918120741844177, -0.5142191648483276, -0....   \n",
       "14  [0.20191602408885956, 0.17535044252872467, 0.1...   \n",
       "18  [-0.4908468425273895, -0.40923216938972473, -0...   \n",
       "\n",
       "                      transcription  \n",
       "3   maybe to morrow it will be cold  \n",
       "6               don't forget jacket  \n",
       "9                    i's began dark  \n",
       "14    that is exactly what happened  \n",
       "18      i wonder what this is about  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0c3d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.sort_values('id')\n",
    "val_features = val_features.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b001be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRAIN_0000'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f983998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdddf085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    693\n",
      "1    678\n",
      "2    687\n",
      "3    682\n",
      "4    578\n",
      "5    682\n",
      "Name: label, dtype: int64\n",
      "label\n",
      "0    174\n",
      "1    170\n",
      "2    172\n",
      "3    170\n",
      "4    144\n",
      "5    171\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_features.label.groupby(train_features.label).count())\n",
    "print(val_features.label.groupby(val_features.label).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "020e991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_features.label.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e78269b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('./data/train_8_text.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9327700-ba8e-4429-abb3-d1f538a8c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features.to_csv('./data/valid_2_text.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2b1e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df_preproc.label\n",
    "train_features2, val_features2, train_targets, test_targets = train_test_split(\n",
    "        train_df_preproc, label,\n",
    "        train_size=0.9,\n",
    "        test_size=0.1,\n",
    "        # random but same for all run, also accurancy depends on the\n",
    "        # selection of data e.g. if we put 10 then accuracy will be 1.0\n",
    "        # in this example\n",
    "        random_state=23,\n",
    "        # keep same proportion of 'target' in test and target data\n",
    "        stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db31d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features2 = train_features2.sort_values('id')\n",
    "val_features2 = val_features2.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8f3296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    780\n",
      "1    763\n",
      "2    773\n",
      "3    767\n",
      "4    650\n",
      "5    767\n",
      "Name: label, dtype: int64\n",
      "label\n",
      "0    87\n",
      "1    85\n",
      "2    86\n",
      "3    85\n",
      "4    72\n",
      "5    86\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_features2.label.groupby(train_features2.label).count())\n",
    "print(val_features2.label.groupby(val_features2.label).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0151cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                    path  label  \\\n",
      "0  TRAIN_0000  ./train/TRAIN_0000.wav      1   \n",
      "1  TRAIN_0001  ./train/TRAIN_0001.wav      2   \n",
      "2  TRAIN_0002  ./train/TRAIN_0002.wav      4   \n",
      "4  TRAIN_0004  ./train/TRAIN_0004.wav      4   \n",
      "5  TRAIN_0005  ./train/TRAIN_0005.wav      3   \n",
      "\n",
      "                                               array  \\\n",
      "0  [1.1033457517623901, 1.2063554525375366, 1.166...   \n",
      "1  [-0.5838981866836548, -0.6609091758728027, -0....   \n",
      "2  [0.27893486618995667, 0.2514820098876953, 0.24...   \n",
      "4  [-0.16494052112102509, -0.15212097764015198, -...   \n",
      "5  [0.10450570285320282, 0.07023542374372482, 0.0...   \n",
      "\n",
      "                       transcription  \n",
      "0                it's eleven o'clock  \n",
      "1               the surface is sleek  \n",
      "2  we'll stop in a couple of minutes  \n",
      "4             donc will get a jacket  \n",
      "5           on my way to the meeting  \n",
      "            id                    path  label  \\\n",
      "3   TRAIN_0003  ./train/TRAIN_0003.wav      5   \n",
      "6   TRAIN_0006  ./train/TRAIN_0006.wav      0   \n",
      "9   TRAIN_0009  ./train/TRAIN_0009.wav      1   \n",
      "20  TRAIN_0020  ./train/TRAIN_0020.wav      3   \n",
      "42  TRAIN_0042  ./train/TRAIN_0042.wav      1   \n",
      "\n",
      "                                                array  \\\n",
      "3   [0.20071503520011902, 0.20071503520011902, 0.2...   \n",
      "6   [-0.016541067510843277, -0.024171410128474236,...   \n",
      "9   [-0.5918120741844177, -0.5142191648483276, -0....   \n",
      "20  [-0.06684936583042145, -0.0796586349606514, -0...   \n",
      "42  [0.1990586817264557, 0.2087838351726532, 0.248...   \n",
      "\n",
      "                      transcription  \n",
      "3   maybe to morrow it will be cold  \n",
      "6               don't forget jacket  \n",
      "9                    i's began dark  \n",
      "20   i would like a new alarm clock  \n",
      "42  maybe to morrow it will be cold  \n"
     ]
    }
   ],
   "source": [
    "print(train_features2.head())\n",
    "print(val_features2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49765183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features2.to_csv('./data/train_9.csv',index=False)\n",
    "val_features2.to_csv('./data/valid_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86d7584e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>./test/TEST_0000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>./test/TEST_0001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>./test/TEST_0002.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>./test/TEST_0003.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>./test/TEST_0004.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                  path\n",
       "0  TEST_0000  ./test/TEST_0000.wav\n",
       "1  TEST_0001  ./test/TEST_0001.wav\n",
       "2  TEST_0002  ./test/TEST_0002.wav\n",
       "3  TEST_0003  ./test/TEST_0003.wav\n",
       "4  TEST_0004  ./test/TEST_0004.wav"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv('./data/test.csv')\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdd4e0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/test/TEST_0000.wav\n"
     ]
    }
   ],
   "source": [
    "paths = t.path.to_list()\n",
    "paths[0] = paths[0].replace('./','./data/')\n",
    "print(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ec3e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df_preproc.label\n",
    "train_features3, val_features3, train_targets, test_targets = train_test_split(\n",
    "        train_df_preproc, label,\n",
    "        train_size=0.95,\n",
    "        test_size=0.05,\n",
    "        # random but same for all run, also accurancy depends on the\n",
    "        # selection of data e.g. if we put 10 then accuracy will be 1.0\n",
    "        # in this example\n",
    "        random_state=1000,\n",
    "        # keep same proportion of 'target' in test and target data\n",
    "        stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c282a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features3 = train_features3.sort_values('id')\n",
    "val_features3 = val_features3.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df4495df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    824\n",
      "1    805\n",
      "2    816\n",
      "3    809\n",
      "4    686\n",
      "5    810\n",
      "Name: label, dtype: int64\n",
      "label\n",
      "0    43\n",
      "1    43\n",
      "2    43\n",
      "3    43\n",
      "4    36\n",
      "5    43\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_features3.label.groupby(train_features3.label).count())\n",
    "print(val_features3.label.groupby(val_features3.label).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ac56a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                    path  label  \\\n",
      "0  TRAIN_0000  ./train/TRAIN_0000.wav      1   \n",
      "1  TRAIN_0001  ./train/TRAIN_0001.wav      2   \n",
      "2  TRAIN_0002  ./train/TRAIN_0002.wav      4   \n",
      "3  TRAIN_0003  ./train/TRAIN_0003.wav      5   \n",
      "4  TRAIN_0004  ./train/TRAIN_0004.wav      4   \n",
      "\n",
      "                                               array  \\\n",
      "0  [1.1033457517623901, 1.2063554525375366, 1.166...   \n",
      "1  [-0.5838981866836548, -0.6609091758728027, -0....   \n",
      "2  [0.27893486618995667, 0.2514820098876953, 0.24...   \n",
      "3  [0.20071503520011902, 0.20071503520011902, 0.2...   \n",
      "4  [-0.16494052112102509, -0.15212097764015198, -...   \n",
      "\n",
      "                       transcription  \n",
      "0                it's eleven o'clock  \n",
      "1               the surface is sleek  \n",
      "2  we'll stop in a couple of minutes  \n",
      "3    maybe to morrow it will be cold  \n",
      "4             donc will get a jacket  \n",
      "            id                    path  label  \\\n",
      "28  TRAIN_0028  ./train/TRAIN_0028.wav      4   \n",
      "38  TRAIN_0038  ./train/TRAIN_0038.wav      2   \n",
      "73  TRAIN_0073  ./train/TRAIN_0073.wav      3   \n",
      "77  TRAIN_0077  ./train/TRAIN_0077.wav      4   \n",
      "89  TRAIN_0089  ./train/TRAIN_0089.wav      0   \n",
      "\n",
      "                                                array  \\\n",
      "28  [-0.19722993671894073, -0.1809421181678772, -0...   \n",
      "38  [0.010614138096570969, 0.03219367191195488, 0....   \n",
      "73  [-0.08863669633865356, -0.058880843222141266, ...   \n",
      "77  [-0.2591564953327179, -0.18984802067279816, -0...   \n",
      "89  [-0.025558294728398323, -0.032482974231243134,...   \n",
      "\n",
      "                            transcription  \n",
      "28  i think i have a doctor's appointment  \n",
      "38     i think i have a gates appointment  \n",
      "73            am on my way to the meeting  \n",
      "77         i would like a new alarm clock  \n",
      "89           i'm on my way to the meaning  \n"
     ]
    }
   ],
   "source": [
    "print(train_features3.head())\n",
    "print(val_features3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31f76cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features3.to_csv('./data/train_95_text.csv',index=False)\n",
    "val_features3.to_csv('./data/valid_05_text.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e04aa09-7d8f-4066-a675-df4cb7618d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preproc.to_csv('./data/test_text.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecd5ffbf-87ce-4540-98d3-c271ecb66256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>array</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./train/TRAIN_0000.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1033457517623901, 1.2063554525375366, 1.166...</td>\n",
       "      <td>it's eleven o'clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./train/TRAIN_0001.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.5838981866836548, -0.6609091758728027, -0....</td>\n",
       "      <td>the surface is sleek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./train/TRAIN_0002.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.27893486618995667, 0.2514820098876953, 0.24...</td>\n",
       "      <td>we'll stop in a couple of minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./train/TRAIN_0003.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.20071503520011902, 0.20071503520011902, 0.2...</td>\n",
       "      <td>maybe to morrow it will be cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./train/TRAIN_0004.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.16494052112102509, -0.15212097764015198, -...</td>\n",
       "      <td>donc will get a jacket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                    path  label  \\\n",
       "0  TRAIN_0000  ./train/TRAIN_0000.wav      1   \n",
       "1  TRAIN_0001  ./train/TRAIN_0001.wav      2   \n",
       "2  TRAIN_0002  ./train/TRAIN_0002.wav      4   \n",
       "3  TRAIN_0003  ./train/TRAIN_0003.wav      5   \n",
       "4  TRAIN_0004  ./train/TRAIN_0004.wav      4   \n",
       "\n",
       "                                               array  \\\n",
       "0  [1.1033457517623901, 1.2063554525375366, 1.166...   \n",
       "1  [-0.5838981866836548, -0.6609091758728027, -0....   \n",
       "2  [0.27893486618995667, 0.2514820098876953, 0.24...   \n",
       "3  [0.20071503520011902, 0.20071503520011902, 0.2...   \n",
       "4  [-0.16494052112102509, -0.15212097764015198, -...   \n",
       "\n",
       "                       transcription  \n",
       "0                it's eleven o'clock  \n",
       "1               the surface is sleek  \n",
       "2  we'll stop in a couple of minutes  \n",
       "3    maybe to morrow it will be cold  \n",
       "4             donc will get a jacket  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23a30bdd-bdd3-4304-b412-8531c811ede7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it's eleven o'clock\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features3.transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1e1668-560b-4aa3-a913-7f80cbbccc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/compat/_optional.py:161: UserWarning: Pandas requires version '2.7.1' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, AutoModelForSequenceClassification, AutoTokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained('tae898/emoberta-large')\n",
    "token = AutoTokenizer.from_pretrained('tae898/emoberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93be549-32cf-4cf5-a968-7b04ee6c41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(sen1, \n",
    "                          sen2, \n",
    "                          return_tensors='pt', \n",
    "                          max_length=MAX_LEN, \n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          add_special_tokens=True,\n",
    "                          return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60edd2ee-e0d7-418f-abb7-d8e8fb3e1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "MAX_LEN = 41\n",
    "item = token('',return_tensors='pt', \n",
    "                          max_length=MAX_LEN, \n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          add_special_tokens=True,\n",
    "                          return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64e0da1-71c6-40a2-b47d-eaf88e6336da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ccd428f-af1d-467d-9335-54a45af2ec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['input_ids'][0][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93ba367d-547f-4d87-9a88-c8c920b68ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(item['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea6d0fb6-5d43-4ca9-8f14-c2b76c57ae2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546dacb-91a0-4848-aa60-c5cc3f8133a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_freeze(w2v2, total_layer,frz_layer) :\n",
    "    w2v2.dropout = nn.Identity()\n",
    "    w2v2.lm_head = nn.Identity()\n",
    "    for para in w2v2.parameters():\n",
    "        para.requires_grad = False\n",
    "\n",
    "    for name ,child in w2v2.named_children():\n",
    "        if name == 'wav2vec2':\n",
    "            for nam,chil in child.named_children():\n",
    "                if nam == 'encoder' :\n",
    "                    for na,chi in chil.named_children():\n",
    "                        if na == 'layers' :\n",
    "                            for i in range(total_layer):\n",
    "                                if frz_layer == -1 :\n",
    "                                    for para in chi.parameters():\n",
    "                                        para.requires_grad = True\n",
    "                                elif frz_layer <= i :\n",
    "                                    for i,para in enumerate(chi[i].parameters()):\n",
    "                                        para.requires_grad = True\n",
    "    return w2v2                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8fad4040-8369-4105-8cfb-e2a9d1425a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClassificationHead(\n",
       "  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79e1c9a2-abec-4274-a204-e1e35f18061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model.classifier.dropout = nn.Identity()\n",
    "model.classifier.out_proj = nn.Linear(1024,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "188588d9-2326-44e9-a407-3f4ef2591ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Identity()\n",
       "    (out_proj): Linear(in_features=1024, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nlp_finetune(emoberta,proj_dim) :\n",
    "    emoberta.classifier.dropout = nn.Identity()\n",
    "    emoberta.classifier.out_proj = nn.Identity()\n",
    "    \n",
    "    for para in emoberta.parameters():\n",
    "        para.requires_grad = False\n",
    "    \n",
    "    emoberta.classifier.out_proj = nn.Linear(1024,proj_dim)\n",
    "    return emoberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f69caf3b-ec55-420d-aa17-ce4c8b71145d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClassificationHead(\n",
       "  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name ,child in model.named_children():\n",
    "    if name == 'classifier' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36a69039-7891-43b0-8b5a-10683c4fbeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 2.5200,  2.9632, -0.9061,  0.4828, -1.2299, -2.8644, -1.6932]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc70e1a0-a936-4bbb-986d-4e0014875dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    MAX_LEN = 41\n",
    "    return token(example,return_tensors='pt', \n",
    "                          max_length=MAX_LEN, \n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          add_special_tokens=True,\n",
    "                          return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4aac4593-81c0-4e68-b16a-70b4f6e14e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_data \u001b[38;5;241m=\u001b[39m train_features3\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28;01mlambda\u001b[39;00m x : tokenize_function(x))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:8924\u001b[0m, in \u001b[0;36mDataFrame.applymap\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m   8921\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(x, func, ignore_na\u001b[38;5;241m=\u001b[39mignore_na)\n\u001b[1;32m   8922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(x\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values, func, ignore_na\u001b[38;5;241m=\u001b[39mignore_na)\n\u001b[0;32m-> 8924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplymap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:8839\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8828\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8830\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   8831\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8832\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8837\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   8838\u001b[0m )\n\u001b[0;32m-> 8839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    869\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    870\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    871\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:8922\u001b[0m, in \u001b[0;36mDataFrame.applymap.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   8920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   8921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(x, func, ignore_na\u001b[38;5;241m=\u001b[39mignore_na)\n\u001b[0;32m-> 8922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_na\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_data \u001b[38;5;241m=\u001b[39m train_features3\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[43mtokenize_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36mtokenize_function\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(example):\n\u001b[1;32m      2\u001b[0m     MAX_LEN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m41\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtoken\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2380\u001b[0m     )\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2385\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2386\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "token_data = train_features3.applymap(lambda x : tokenize_function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3bed9014-94a1-4142-8f6a-d57298608174",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_data' is not defined"
     ]
    }
   ],
   "source": [
    "token_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164e9ea-aaee-45c4-a549-b0a39c6dcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 41\n",
    "item = token(train_features3.transcription,return_tensors='pt', \n",
    "                          max_length=MAX_LEN, \n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          add_special_tokens=True,\n",
    "                          return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf2a865-1c25-4687-99c5-6f6cf38796ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]])\n\u001b[1;32m      4\u001b[0m c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]])\n\u001b[0;32m----> 5\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((a,b),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((a,c),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.empty()\n",
    "b = np.array([[1,2,3,4]])\n",
    "c = np.array([[2,3,4,5]])\n",
    "a = np.concatenate((a,b),axis=0)\n",
    "a = np.concatenate((a,c),axis=0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58fad2d3-7e30-47ee-a334-0835add124ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([2, 4])\n",
      "tensor([1., 2., 3., 4.])\n",
      "tensor([2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.empty(0)\n",
    "b = torch.tensor([[1,2,3,4]])\n",
    "c = torch.tensor([[2,3,4,5]])\n",
    "a = torch.cat((a,b),0)\n",
    "a = torch.cat((a,c),0)\n",
    "print(len(a))\n",
    "print(a.shape)\n",
    "for i in a :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ec7ad548-103c-4d89-8c1e-fba7841c11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.arange(1,64*30+1).reshape(1,2,32,30)  # >>> (50,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4ac08242-dd63-4221-a065-fda5df79c551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[   1,    2,    3,  ...,   28,   29,   30],\n",
       "          [  31,   32,   33,  ...,   58,   59,   60],\n",
       "          [  61,   62,   63,  ...,   88,   89,   90],\n",
       "          ...,\n",
       "          [ 871,  872,  873,  ...,  898,  899,  900],\n",
       "          [ 901,  902,  903,  ...,  928,  929,  930],\n",
       "          [ 931,  932,  933,  ...,  958,  959,  960]],\n",
       "\n",
       "         [[ 961,  962,  963,  ...,  988,  989,  990],\n",
       "          [ 991,  992,  993,  ..., 1018, 1019, 1020],\n",
       "          [1021, 1022, 1023,  ..., 1048, 1049, 1050],\n",
       "          ...,\n",
       "          [1831, 1832, 1833,  ..., 1858, 1859, 1860],\n",
       "          [1861, 1862, 1863,  ..., 1888, 1889, 1890],\n",
       "          [1891, 1892, 1893,  ..., 1918, 1919, 1920]]]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "35a701d8-90a9-4fbd-911b-910ba30d3498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2, 2, 16, 15])\n",
      "torch.Size([1, 8, 16, 15])\n",
      "tensor([ 16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "         30,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
      "         59,  60,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "         88,  89,  90, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
      "        146, 147, 148, 149, 150, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "        175, 176, 177, 178, 179, 180, 196, 197, 198, 199, 200, 201, 202, 203,\n",
      "        204, 205, 206, 207, 208, 209, 210, 226, 227, 228, 229, 230, 231, 232,\n",
      "        233, 234, 235, 236, 237, 238, 239, 240, 256, 257, 258, 259, 260, 261,\n",
      "        262, 263, 264, 265, 266, 267, 268, 269, 270, 286, 287, 288, 289, 290,\n",
      "        291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 316, 317, 318, 319,\n",
      "        320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 346, 347, 348,\n",
      "        349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 406,\n",
      "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
      "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
      "        450, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
      "        479, 480])\n"
     ]
    }
   ],
   "source": [
    "print(a.unfold(2,16,16).unfold(3,15,15).shape)\n",
    "print(a.unfold(2,16,16).unfold(3,15,15).reshape(1,-1,16,15).shape)\n",
    "fold = a.unfold(2,16,16).unfold(3,15,15).reshape(1,-1,16,15).reshape(1,-1,16*15)\n",
    "print(fold[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "57d25406-2db6-4dbf-b883-afd1134f384f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80//16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "89ec9f3f-eefd-4d4a-97d3-5e99fbca31af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   1,    2,    3,    4,    5],\n",
       "         [  51,   52,   53,   54,   55],\n",
       "         [ 101,  102,  103,  104,  105],\n",
       "         [ 151,  152,  153,  154,  155]],\n",
       "\n",
       "        [[   6,    7,    8,    9,   10],\n",
       "         [  56,   57,   58,   59,   60],\n",
       "         [ 106,  107,  108,  109,  110],\n",
       "         [ 156,  157,  158,  159,  160]],\n",
       "\n",
       "        [[  11,   12,   13,   14,   15],\n",
       "         [  61,   62,   63,   64,   65],\n",
       "         [ 111,  112,  113,  114,  115],\n",
       "         [ 161,  162,  163,  164,  165]],\n",
       "\n",
       "        [[  16,   17,   18,   19,   20],\n",
       "         [  66,   67,   68,   69,   70],\n",
       "         [ 116,  117,  118,  119,  120],\n",
       "         [ 166,  167,  168,  169,  170]],\n",
       "\n",
       "        [[  21,   22,   23,   24,   25],\n",
       "         [  71,   72,   73,   74,   75],\n",
       "         [ 121,  122,  123,  124,  125],\n",
       "         [ 171,  172,  173,  174,  175]],\n",
       "\n",
       "        [[  26,   27,   28,   29,   30],\n",
       "         [  76,   77,   78,   79,   80],\n",
       "         [ 126,  127,  128,  129,  130],\n",
       "         [ 176,  177,  178,  179,  180]],\n",
       "\n",
       "        [[  31,   32,   33,   34,   35],\n",
       "         [  81,   82,   83,   84,   85],\n",
       "         [ 131,  132,  133,  134,  135],\n",
       "         [ 181,  182,  183,  184,  185]],\n",
       "\n",
       "        [[  36,   37,   38,   39,   40],\n",
       "         [  86,   87,   88,   89,   90],\n",
       "         [ 136,  137,  138,  139,  140],\n",
       "         [ 186,  187,  188,  189,  190]],\n",
       "\n",
       "        [[  41,   42,   43,   44,   45],\n",
       "         [  91,   92,   93,   94,   95],\n",
       "         [ 141,  142,  143,  144,  145],\n",
       "         [ 191,  192,  193,  194,  195]],\n",
       "\n",
       "        [[  46,   47,   48,   49,   50],\n",
       "         [  96,   97,   98,   99,  100],\n",
       "         [ 146,  147,  148,  149,  150],\n",
       "         [ 196,  197,  198,  199,  200]],\n",
       "\n",
       "        [[ 201,  202,  203,  204,  205],\n",
       "         [ 251,  252,  253,  254,  255],\n",
       "         [ 301,  302,  303,  304,  305],\n",
       "         [ 351,  352,  353,  354,  355]],\n",
       "\n",
       "        [[ 206,  207,  208,  209,  210],\n",
       "         [ 256,  257,  258,  259,  260],\n",
       "         [ 306,  307,  308,  309,  310],\n",
       "         [ 356,  357,  358,  359,  360]],\n",
       "\n",
       "        [[ 211,  212,  213,  214,  215],\n",
       "         [ 261,  262,  263,  264,  265],\n",
       "         [ 311,  312,  313,  314,  315],\n",
       "         [ 361,  362,  363,  364,  365]],\n",
       "\n",
       "        [[ 216,  217,  218,  219,  220],\n",
       "         [ 266,  267,  268,  269,  270],\n",
       "         [ 316,  317,  318,  319,  320],\n",
       "         [ 366,  367,  368,  369,  370]],\n",
       "\n",
       "        [[ 221,  222,  223,  224,  225],\n",
       "         [ 271,  272,  273,  274,  275],\n",
       "         [ 321,  322,  323,  324,  325],\n",
       "         [ 371,  372,  373,  374,  375]],\n",
       "\n",
       "        [[ 226,  227,  228,  229,  230],\n",
       "         [ 276,  277,  278,  279,  280],\n",
       "         [ 326,  327,  328,  329,  330],\n",
       "         [ 376,  377,  378,  379,  380]],\n",
       "\n",
       "        [[ 231,  232,  233,  234,  235],\n",
       "         [ 281,  282,  283,  284,  285],\n",
       "         [ 331,  332,  333,  334,  335],\n",
       "         [ 381,  382,  383,  384,  385]],\n",
       "\n",
       "        [[ 236,  237,  238,  239,  240],\n",
       "         [ 286,  287,  288,  289,  290],\n",
       "         [ 336,  337,  338,  339,  340],\n",
       "         [ 386,  387,  388,  389,  390]],\n",
       "\n",
       "        [[ 241,  242,  243,  244,  245],\n",
       "         [ 291,  292,  293,  294,  295],\n",
       "         [ 341,  342,  343,  344,  345],\n",
       "         [ 391,  392,  393,  394,  395]],\n",
       "\n",
       "        [[ 246,  247,  248,  249,  250],\n",
       "         [ 296,  297,  298,  299,  300],\n",
       "         [ 346,  347,  348,  349,  350],\n",
       "         [ 396,  397,  398,  399,  400]],\n",
       "\n",
       "        [[ 401,  402,  403,  404,  405],\n",
       "         [ 451,  452,  453,  454,  455],\n",
       "         [ 501,  502,  503,  504,  505],\n",
       "         [ 551,  552,  553,  554,  555]],\n",
       "\n",
       "        [[ 406,  407,  408,  409,  410],\n",
       "         [ 456,  457,  458,  459,  460],\n",
       "         [ 506,  507,  508,  509,  510],\n",
       "         [ 556,  557,  558,  559,  560]],\n",
       "\n",
       "        [[ 411,  412,  413,  414,  415],\n",
       "         [ 461,  462,  463,  464,  465],\n",
       "         [ 511,  512,  513,  514,  515],\n",
       "         [ 561,  562,  563,  564,  565]],\n",
       "\n",
       "        [[ 416,  417,  418,  419,  420],\n",
       "         [ 466,  467,  468,  469,  470],\n",
       "         [ 516,  517,  518,  519,  520],\n",
       "         [ 566,  567,  568,  569,  570]],\n",
       "\n",
       "        [[ 421,  422,  423,  424,  425],\n",
       "         [ 471,  472,  473,  474,  475],\n",
       "         [ 521,  522,  523,  524,  525],\n",
       "         [ 571,  572,  573,  574,  575]],\n",
       "\n",
       "        [[ 426,  427,  428,  429,  430],\n",
       "         [ 476,  477,  478,  479,  480],\n",
       "         [ 526,  527,  528,  529,  530],\n",
       "         [ 576,  577,  578,  579,  580]],\n",
       "\n",
       "        [[ 431,  432,  433,  434,  435],\n",
       "         [ 481,  482,  483,  484,  485],\n",
       "         [ 531,  532,  533,  534,  535],\n",
       "         [ 581,  582,  583,  584,  585]],\n",
       "\n",
       "        [[ 436,  437,  438,  439,  440],\n",
       "         [ 486,  487,  488,  489,  490],\n",
       "         [ 536,  537,  538,  539,  540],\n",
       "         [ 586,  587,  588,  589,  590]],\n",
       "\n",
       "        [[ 441,  442,  443,  444,  445],\n",
       "         [ 491,  492,  493,  494,  495],\n",
       "         [ 541,  542,  543,  544,  545],\n",
       "         [ 591,  592,  593,  594,  595]],\n",
       "\n",
       "        [[ 446,  447,  448,  449,  450],\n",
       "         [ 496,  497,  498,  499,  500],\n",
       "         [ 546,  547,  548,  549,  550],\n",
       "         [ 596,  597,  598,  599,  600]],\n",
       "\n",
       "        [[ 601,  602,  603,  604,  605],\n",
       "         [ 651,  652,  653,  654,  655],\n",
       "         [ 701,  702,  703,  704,  705],\n",
       "         [ 751,  752,  753,  754,  755]],\n",
       "\n",
       "        [[ 606,  607,  608,  609,  610],\n",
       "         [ 656,  657,  658,  659,  660],\n",
       "         [ 706,  707,  708,  709,  710],\n",
       "         [ 756,  757,  758,  759,  760]],\n",
       "\n",
       "        [[ 611,  612,  613,  614,  615],\n",
       "         [ 661,  662,  663,  664,  665],\n",
       "         [ 711,  712,  713,  714,  715],\n",
       "         [ 761,  762,  763,  764,  765]],\n",
       "\n",
       "        [[ 616,  617,  618,  619,  620],\n",
       "         [ 666,  667,  668,  669,  670],\n",
       "         [ 716,  717,  718,  719,  720],\n",
       "         [ 766,  767,  768,  769,  770]],\n",
       "\n",
       "        [[ 621,  622,  623,  624,  625],\n",
       "         [ 671,  672,  673,  674,  675],\n",
       "         [ 721,  722,  723,  724,  725],\n",
       "         [ 771,  772,  773,  774,  775]],\n",
       "\n",
       "        [[ 626,  627,  628,  629,  630],\n",
       "         [ 676,  677,  678,  679,  680],\n",
       "         [ 726,  727,  728,  729,  730],\n",
       "         [ 776,  777,  778,  779,  780]],\n",
       "\n",
       "        [[ 631,  632,  633,  634,  635],\n",
       "         [ 681,  682,  683,  684,  685],\n",
       "         [ 731,  732,  733,  734,  735],\n",
       "         [ 781,  782,  783,  784,  785]],\n",
       "\n",
       "        [[ 636,  637,  638,  639,  640],\n",
       "         [ 686,  687,  688,  689,  690],\n",
       "         [ 736,  737,  738,  739,  740],\n",
       "         [ 786,  787,  788,  789,  790]],\n",
       "\n",
       "        [[ 641,  642,  643,  644,  645],\n",
       "         [ 691,  692,  693,  694,  695],\n",
       "         [ 741,  742,  743,  744,  745],\n",
       "         [ 791,  792,  793,  794,  795]],\n",
       "\n",
       "        [[ 646,  647,  648,  649,  650],\n",
       "         [ 696,  697,  698,  699,  700],\n",
       "         [ 746,  747,  748,  749,  750],\n",
       "         [ 796,  797,  798,  799,  800]],\n",
       "\n",
       "        [[ 801,  802,  803,  804,  805],\n",
       "         [ 851,  852,  853,  854,  855],\n",
       "         [ 901,  902,  903,  904,  905],\n",
       "         [ 951,  952,  953,  954,  955]],\n",
       "\n",
       "        [[ 806,  807,  808,  809,  810],\n",
       "         [ 856,  857,  858,  859,  860],\n",
       "         [ 906,  907,  908,  909,  910],\n",
       "         [ 956,  957,  958,  959,  960]],\n",
       "\n",
       "        [[ 811,  812,  813,  814,  815],\n",
       "         [ 861,  862,  863,  864,  865],\n",
       "         [ 911,  912,  913,  914,  915],\n",
       "         [ 961,  962,  963,  964,  965]],\n",
       "\n",
       "        [[ 816,  817,  818,  819,  820],\n",
       "         [ 866,  867,  868,  869,  870],\n",
       "         [ 916,  917,  918,  919,  920],\n",
       "         [ 966,  967,  968,  969,  970]],\n",
       "\n",
       "        [[ 821,  822,  823,  824,  825],\n",
       "         [ 871,  872,  873,  874,  875],\n",
       "         [ 921,  922,  923,  924,  925],\n",
       "         [ 971,  972,  973,  974,  975]],\n",
       "\n",
       "        [[ 826,  827,  828,  829,  830],\n",
       "         [ 876,  877,  878,  879,  880],\n",
       "         [ 926,  927,  928,  929,  930],\n",
       "         [ 976,  977,  978,  979,  980]],\n",
       "\n",
       "        [[ 831,  832,  833,  834,  835],\n",
       "         [ 881,  882,  883,  884,  885],\n",
       "         [ 931,  932,  933,  934,  935],\n",
       "         [ 981,  982,  983,  984,  985]],\n",
       "\n",
       "        [[ 836,  837,  838,  839,  840],\n",
       "         [ 886,  887,  888,  889,  890],\n",
       "         [ 936,  937,  938,  939,  940],\n",
       "         [ 986,  987,  988,  989,  990]],\n",
       "\n",
       "        [[ 841,  842,  843,  844,  845],\n",
       "         [ 891,  892,  893,  894,  895],\n",
       "         [ 941,  942,  943,  944,  945],\n",
       "         [ 991,  992,  993,  994,  995]],\n",
       "\n",
       "        [[ 846,  847,  848,  849,  850],\n",
       "         [ 896,  897,  898,  899,  900],\n",
       "         [ 946,  947,  948,  949,  950],\n",
       "         [ 996,  997,  998,  999, 1000]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unfold(0,4,4).unfold(1,5,5).reshape(-1,4,5)#.unfold(1,1,1)..shape#.unfold(0,4,4).shape   #torch.Size([20, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029dcf22-6f78-4d46-8564-a9ebbe6a7454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/tae_test.pk\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517331f7-0cb0-43fe-9d9c-67a0a0a34da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9335010e-4883-487d-93d9-98cd16a7459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/compat/_optional.py:161: UserWarning: Pandas requires version '2.7.1' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv('./data/train_95.csv')\n",
    "b = pd.read_csv('./data/train_95_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b071ec97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "4745    True\n",
       "4746    True\n",
       "4747    True\n",
       "4748    True\n",
       "4749    True\n",
       "Name: id, Length: 4750, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.id == b.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8193a37c-4122-46ec-9b7e-04a6e15bb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open('./exp_result/emotion_wav2vec2_ecapa_ep500_bs128_lr0.0001_w2v2_TL12_frz3_ECAPA_sec2_large960h/emotion_wav2vec2_ecapa_ep500_bs128_lr0.0001_w2v2_TL12_frz3_ECAPA_sec2_large960h_0_test.pk','rb') as f :\n",
    "    data = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a19381c7-5b18-4bef-9425-3f765391a76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.5931e-01, -5.3774e-01,  1.5433e-03,  2.4787e-01, -1.9911e+00,\n",
       "        -1.0509e+00, -1.4639e+00, -2.7565e-01,  5.4115e-01,  4.5843e-01,\n",
       "         1.2530e+00,  4.2078e-01,  2.6696e+00,  4.6399e-01,  4.3135e-01,\n",
       "        -4.8051e-01, -2.0536e-01, -3.9583e-01,  1.0609e+00,  2.5568e-01,\n",
       "         2.1997e+00,  6.3506e-01, -1.3137e+00, -3.5281e-01, -2.0038e-01,\n",
       "         6.1724e-01, -3.1791e+00,  3.1838e-01, -1.8482e+00, -4.5679e-02,\n",
       "        -2.5816e-01,  2.7996e-01,  1.0450e+00, -8.3801e-01, -3.7754e-01,\n",
       "         7.5415e-01,  9.6495e-01, -3.5338e-02,  4.1465e-01,  4.9571e-01,\n",
       "         1.3334e+00,  5.9965e-01, -1.0873e+00,  4.0840e-01,  1.5291e+00,\n",
       "         1.6057e+00, -9.0559e-01,  5.4135e-01,  4.0631e-01, -6.1569e-01,\n",
       "        -1.1371e+00,  2.1222e+00, -1.0538e+00, -1.1360e+00,  3.5057e-01,\n",
       "         1.6477e+00,  1.5685e+00, -1.3485e+00, -2.1581e+00,  2.3268e+00,\n",
       "         1.1194e+00,  3.5719e-01, -1.4060e+00,  9.3288e-01,  4.0640e-01,\n",
       "        -1.2192e+00, -3.1115e-01,  1.2318e+00,  1.4725e-01,  4.3020e-01,\n",
       "        -1.6168e+00, -1.1350e+00, -2.1362e+00, -1.2832e-01,  1.1576e+00,\n",
       "         1.4181e+00,  8.6342e-01,  3.3716e-01, -2.3867e+00, -1.9102e-01,\n",
       "         1.7309e-01, -5.6872e-01,  1.3307e-01, -1.2456e+00, -3.4120e-01,\n",
       "        -1.3726e+00, -1.0025e+00, -1.3190e+00, -7.5841e-01, -9.3118e-01,\n",
       "         3.6432e-01,  1.5836e+00,  2.0401e+00, -2.0683e+00,  1.1535e+00,\n",
       "         7.7866e-01,  5.7060e-01,  1.1627e+00, -1.3965e+00,  4.4862e-01,\n",
       "        -3.7352e-01,  3.1168e-01,  7.5403e-01, -9.9199e-01,  6.5641e-01,\n",
       "         1.1447e+00, -2.6396e-02, -1.9709e-01,  1.9638e+00, -3.8832e-01,\n",
       "         1.1507e+00,  2.6155e+00, -5.7655e-01,  6.1499e-01, -1.0590e+00,\n",
       "        -2.7526e+00, -1.6912e-01,  1.7260e+00, -1.5841e+00, -2.0233e-02,\n",
       "        -7.9225e-01, -2.8461e-02, -1.7223e+00,  9.8705e-01,  2.3305e-01,\n",
       "        -1.6405e+00, -6.4441e-01,  1.7864e+00,  1.0523e+00, -1.0454e+00,\n",
       "        -2.0029e-01,  3.1430e-01,  1.8690e+00, -1.4877e-02,  4.4654e-01,\n",
       "         1.4439e+00,  1.1227e-01,  8.0752e-01, -4.6224e-01,  9.4359e-03,\n",
       "        -3.6321e-01,  2.4779e+00,  1.0845e+00, -4.0682e-01,  1.9357e+00,\n",
       "        -1.2719e+00,  2.9902e-01,  1.3020e+00,  4.4000e-01, -7.3639e-01,\n",
       "         5.6548e-01,  4.4637e-01,  1.0826e-01, -8.9218e-01,  1.3053e+00,\n",
       "        -4.5730e-01, -1.5653e-01,  3.0145e-01,  3.8225e-01,  1.9567e-01,\n",
       "        -1.4984e+00,  7.3609e-01, -1.7768e+00,  1.9030e+00,  1.1557e+00,\n",
       "        -1.6043e+00,  1.2235e+00, -1.0547e+00, -1.6469e+00, -3.2778e-01,\n",
       "        -4.0389e-01,  1.7057e-02, -6.5772e-01, -5.2931e-01, -5.8507e-01,\n",
       "        -2.7660e+00, -3.7066e-01,  7.2294e-01, -4.9165e-01, -1.0099e+00,\n",
       "        -7.8948e-01, -1.7819e-02, -9.6893e-01,  1.6993e+00, -3.5661e-01,\n",
       "         1.6536e-01,  4.4148e-02,  9.8255e-02, -9.2746e-02,  6.7519e-02,\n",
       "         1.3269e+00,  1.8952e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TEST_0000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c402b-ee6d-4419-9c73-0c3f30f1cddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc40a6-21a0-4d5a-aa17-4f8da4b8ee8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee213cfc-a941-485a-85a9-d0e5ca3fb5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./data/train_95_text.csv')\n",
    "valid_df = pd.read_csv('./data/valid_05_text.csv')\n",
    "test_df = pd.read_csv('./data/test_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5701928f-040a-4d3a-b55e-b1b0f1e9ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, RobertaModel, AutoModel\n",
    "from transformers import BertModel, RobertaTokenizer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e14f842-9ad5-458b-94da-e5bf2f745cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>array</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./train/TRAIN_0000.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1033457517623901, 1.2063554525375366, 1.166...</td>\n",
       "      <td>it's eleven o'clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./train/TRAIN_0001.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.5838981866836548, -0.6609091758728027, -0....</td>\n",
       "      <td>the surface is sleek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./train/TRAIN_0002.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.27893486618995667, 0.2514820098876953, 0.24...</td>\n",
       "      <td>we'll stop in a couple of minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./train/TRAIN_0003.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.20071503520011902, 0.20071503520011902, 0.2...</td>\n",
       "      <td>maybe to morrow it will be cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./train/TRAIN_0004.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.16494052112102509, -0.15212097764015198, -...</td>\n",
       "      <td>donc will get a jacket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                    path  label  \\\n",
       "0  TRAIN_0000  ./train/TRAIN_0000.wav      1   \n",
       "1  TRAIN_0001  ./train/TRAIN_0001.wav      2   \n",
       "2  TRAIN_0002  ./train/TRAIN_0002.wav      4   \n",
       "3  TRAIN_0003  ./train/TRAIN_0003.wav      5   \n",
       "4  TRAIN_0004  ./train/TRAIN_0004.wav      4   \n",
       "\n",
       "                                               array  \\\n",
       "0  [1.1033457517623901, 1.2063554525375366, 1.166...   \n",
       "1  [-0.5838981866836548, -0.6609091758728027, -0....   \n",
       "2  [0.27893486618995667, 0.2514820098876953, 0.24...   \n",
       "3  [0.20071503520011902, 0.20071503520011902, 0.2...   \n",
       "4  [-0.16494052112102509, -0.15212097764015198, -...   \n",
       "\n",
       "                       transcription  \n",
       "0                it's eleven o'clock  \n",
       "1               the surface is sleek  \n",
       "2  we'll stop in a couple of minutes  \n",
       "3    maybe to morrow it will be cold  \n",
       "4             donc will get a jacket  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06e68ed4-e0a2-4da2-a72f-1dea0ef471ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = train_df.transcription\n",
    "valid_trans = valid_df.transcription\n",
    "test_trans = test_df.transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61e82b65-bcb0-4248-8dde-66379abda572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's eleven o'clock\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(train_trans) :\n",
    "    if i == 0 :\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f8eb6f2-1834-4e51-b34e-25570842a1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tae898/emoberta-large were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at tae898/emoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained('tae898/emoberta-large')\n",
    "bert = AutoModel.from_pretrained(\"tae898/emoberta-large\")\n",
    "bert.pooler = torch.nn.Identity()\n",
    "MAX_LEN = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b383c12-358f-429d-b975-1032735ecd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71fb2031-39a6-4b25-8675-c5cceb49a68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pooled_list = []\n",
    "\n",
    "for i, trans in tqdm(enumerate(train_trans)) :\n",
    "    \n",
    "    item = tokenizer(trans,return_tensors='pt', \n",
    "                              max_length=MAX_LEN, \n",
    "                              padding='max_length',\n",
    "                              truncation=True,\n",
    "                              add_special_tokens=True,\n",
    "                              return_token_type_ids=True)\n",
    "    input_ids = item['input_ids'][0][None]\n",
    "\n",
    "    attention_mask = item['attention_mask'][0][None]\n",
    "    _, pooled_output = bert(input_ids= input_ids, attention_mask=attention_mask,return_dict=False)\n",
    "    pooled_output = pooled_output[0]\n",
    "    pooled_output, _  = torch.max(pooled_output,0)\n",
    "    pooled_output = pooled_output.detach().numpy()\n",
    "    train_pooled_list.append(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47c89a74-a2e5-448f-9fc7-c86107895f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 251/251 [27:36<00:00,  6.60s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_pooled_list = []\n",
    "\n",
    "for  trans in tqdm.tqdm(valid_trans) :\n",
    "    \n",
    "    item = tokenizer(trans,return_tensors='pt', \n",
    "                              max_length=MAX_LEN, \n",
    "                              padding='max_length',\n",
    "                              truncation=True,\n",
    "                              add_special_tokens=True,\n",
    "                              return_token_type_ids=True)\n",
    "    input_ids = item['input_ids'][0][None]\n",
    "\n",
    "    attention_mask = item['attention_mask'][0][None]\n",
    "    _, pooled_output = bert(input_ids= input_ids, attention_mask=attention_mask,return_dict=False)\n",
    "    pooled_output = pooled_output[0]\n",
    "    pooled_output, _  = torch.max(pooled_output,0)\n",
    "    pooled_output = pooled_output.detach().numpy()\n",
    "    valid_pooled_list.append(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b35b6-a88e-4de4-a726-a880bdf3259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pooled_list = []\n",
    "\n",
    "for i, trans in tqdm(enumerate(test_trans)) :\n",
    "    \n",
    "    item = tokenizer(trans,return_tensors='pt', \n",
    "                              max_length=MAX_LEN, \n",
    "                              padding='max_length',\n",
    "                              truncation=True,\n",
    "                              add_special_tokens=True,\n",
    "                              return_token_type_ids=True)\n",
    "    input_ids = item['input_ids'][0][None]\n",
    "\n",
    "    attention_mask = item['attention_mask'][0][None]\n",
    "    _, pooled_output = bert(input_ids= input_ids, attention_mask=attention_mask,return_dict=False)\n",
    "    pooled_output = pooled_output[0]\n",
    "    pooled_output, _  = torch.max(pooled_output,0)\n",
    "    pooled_output = pooled_output.detach().numpy()\n",
    "    test_pooled_list.append(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c884899-6b6c-4196-9bd1-1a4edb4c6dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d2829e-48cc-483f-b3ed-af6c2c4c4460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   405,    18, 19353,  1021,   108, 17036,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "[[[-1.3277221   1.113966    0.3361138  ... -0.64048487 -1.9860672\n",
      "   -0.4000356 ]\n",
      "  [-0.50834113  0.9026009   0.61659724 ... -0.42300978 -1.7451657\n",
      "   -0.1691581 ]\n",
      "  [-0.99572664  0.9638553   0.3892484  ... -0.5185581  -1.5061496\n",
      "   -0.30227453]\n",
      "  ...\n",
      "  [-0.64973897  0.9461859   0.49465573 ... -0.642866   -1.7621087\n",
      "   -0.2309233 ]\n",
      "  [-0.64973897  0.9461859   0.49465573 ... -0.642866   -1.7621087\n",
      "   -0.2309233 ]\n",
      "  [-0.64973897  0.9461859   0.49465573 ... -0.642866   -1.7621087\n",
      "   -0.2309233 ]]]\n",
      "tensor([[    0,   405,    18, 19353,  1021,   108, 17036,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "torch.Size([1, 41])\n",
      "torch.Size([41, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(attention_mask)\n",
    "print(pooled_output.detach().numpy())\n",
    "print(input_ids)\n",
    "print(attention_mask.shape)\n",
    "print(pooled_output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c51bc-fe68-4511-8dd0-9287ea31b708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc26fd-3b60-431f-8708-18e88ec52be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81603df6-7960-4973-beaf-de354816c886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683477f6-cdb1-4eee-a5e8-eddec2de8c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314ce70-38d0-4225-baef-c1037378d7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2801fd-3cbd-4e89-8950-db36c0374e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632ccb8-c458-472d-a773-3f73aa001750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93fba5-21c1-47f6-b1bb-2832f05811ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecc43d-b088-4059-be38-9036d18d500c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b6322-af15-454b-9769-34555f3bd36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3d858-144b-47df-8227-868bdee3a7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c85c2-71d5-4458-ad66-807431cf5805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09f625-9f8a-4333-93b7-1da1013a94fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea30392-9718-4d2b-ba9d-67ef3a3a55d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abe51a-6a8e-484b-b4aa-29f5a79c5643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514aa578-b5a5-4940-9a2f-d11030ce8a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.11 (NGC 22.02/Python 3.8 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
